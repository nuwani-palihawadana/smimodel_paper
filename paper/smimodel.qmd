---
title: "Sparse Multiple Index Models for High-dimensional Nonparametric Forecasting"
author:
- name: Nuwani K Palihawadana
  affiliations:
    - name: Monash University
      department: Department of Econometrics & Business Statistics
      city: Clayton VIC
      country: Australia
      postal-code: 3800
  email: nuwani.kodikarapalihawadana@monash.edu
  corresponding: true
- name: Rob J Hyndman
  affiliations:
    - name: Monash University
      department: Department of Econometrics & Business Statistics
      city: Clayton VIC
      country: Australia
      postal-code: 3800
  email: rob.hyndman@monash.edu
- name: Xiaoqian&nbsp;Wang
  affiliations:
    - name: Monash University
      department: Department of Econometrics & Business Statistics
      city: Clayton VIC
      country: Australia
      postal-code: 3800
  email: xiaoqian.wang@monash.edu
abstract: Forecasting often involves high-dimensional predictors which have nonlinear relationships with the outcome of interest. Nonparametric additive index models can capture these relationships, while addressing the curse of dimensionality. This paper introduces a new algorithm, ***S***parse ***M***ultiple ***I***ndex (***SMI***) ***Modelling***, tailored for estimating high-dimensional nonparametric/semi-parametric additive index models, while limiting the number of parameters to estimate, by optimising predictor selection and predictor grouping. The SMI Modelling algorithm uses an iterative approach based on mixed integer programming to solve an $\ell_{0}$-regularised nonlinear least squares optimisation problem with linear constraints. We demonstrate the performance of the proposed algorithm through a simulation study, along with two empirical applications to forecast heat-related daily mortality and daily solar intensity.
keywords: [Additive index models, Variable selection, Dimension reduction, Predictor grouping, Mixed integer programming]
bibliography: references.bib
wpnumber: no/yr
jelcodes: C10,C14,C22
blind: false
cover: true
keep-tex: true
include-in-header:
  - text: |
      \usepackage{todonotes}
format:
  wp-pdf:
    knitr:
      opts_chunk:
        dev: "CairoPDF"
execute:
  echo: false
  warning: false
  message: false
  cache: true
---

```{r}
#| label: load
#| cache: false
# Load all required packages
library(tsibble)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(knitr)
library(kableExtra)
options(knitr.kable.NA = '')
theme_set(theme_get() + theme(text = element_text(family = "Source Sans Pro")))
```

# Introduction {#sec-introduction}

Forecasts are often contingent on a very long history of predictors, which are nonlinearly related to the variable of interest. For example, when forecasting half-hourly electricity demand, it is common to use at least a week of historical half-hourly temperatures and other weather observations [@HF2010]. The relationships between lagged temperatures and electricity demand are nonlinear (due to both heating and cooling effects), and involve complex interactions due to thermal inertia in buildings [@FH2012]. Similarly, when forecasting bore levels, rainfall data from up to a thousand days earlier can impact the result [@Peterson2014;@Bakker2019;@Rajaee2019] due to the complex nonlinear flow dynamics of rainfall into aquifers.

These examples suggest a possible nonlinear "*transfer function*" model of the form
$$
 y_t = f(\bm{x}_{t}, \bm{x}_{t-1}, \dots,\bm{x}_{t-p}, y_{t-1},\dots,y_{t-k}) + \varepsilon_{t},
$$
where $y_{t}$ is the observation of the response variable at time $t$, $\bm{x}_{t}$ is a vector of predictors at time $t$, and $\varepsilon_{t}$ is an i.i.d. random error. By including lagged values of $y_{t}$ along with the lagged predictors, the model is able to capture the serial correlation that is present in the data.

The form of $f$ is typically nonlinear and involves complicated interactions with a high value of $p$ (and possibly also a large $k$). It is infeasible to estimate $f$ in high-dimensional settings (where $p$ is large) due to the curse of dimensionality [@Bellman57; @Stone82]. Instead, we normally impose some form of additivity constraint, and ignore interactions of more than two or three variables. There are also numerous ad hoc model choices in selecting the appropriate predictors to include.

For example, @FH2012 proposed a ***semi-parametric additive model*** to obtain short-term forecasts of the half-hourly electricity demand for power systems in the Australian National Electricity Market. In this model, $f$ is assumed to be fully additive, and is used to capture the effects of recent predictor values on the demand. The main objective is to allow nonparametric components in a regression-based modelling framework, particularly to address serially correlated errors. The model fitted for each half-hourly period ($q$) can be written as
$$
 \log(y_{t,q}) = h_{q}(t) + f_{q}(\bm{w}_{1,t},\bm{w}_{2,t}) + \sum_{j=1}^k a_{q,j}(y_{t-j}) + \varepsilon_{t}.
$$
The term $h_{q}(t)$ models several calendar effects as either linear or smooth terms. Temperature effects are modelled using the nonparametric component $f_{q}(\bm{w}_{1,t},\bm{w}_{2,t})$, where $\bm{w}_{i,t} = [w_{i,t},\dots,w_{i,t-p}]'$ is a vector of lagged temperatures at site $i$. The terms $a_{q,j}(y_{t-j})$ capture the lagged effects of the response. Note that the error term $\varepsilon_{t}$ is serially uncorrelated within each half-hourly model, because the serial correlation is eliminated by the inclusion of lagged responses in the model. However, some correlation may still exist between residuals from various half-hourly models [@FH2012].

Similarly, a ***distributed lag model*** was proposed by @Wood2017 to forecast daily death rates in Chicago using measurements of several air pollutants. The response variable is modelled via a sum of smooth functions of lagged predictor variables, which is quite similar to the semi-parametric additive model used by @FH2012. However, unlike in @FH2012, @Wood2017 suggested allowing the smooth functions for lags of the same covariate to vary smoothly over lags, preventing large differences in estimated effects between adjacent lags. Thus, the model is of the form
$$
 \log(y_{t}) = f_{1}(t) + \sum_{k=0}^{K} f_{2}(p_{t-k}, k) + \sum_{k=0}^{K} f_{3}(o_{t-k}, w_{t-k}, k),
$$
where $y_{t}$ is the death rate at day $t$, $f_{1}$ is a nonparametric term to capture the time effect, and $p_t$, $o_t$, and $w_t$ are various predictor variables. The model incorporates the current value ($k = 0$) and several lagged values ($k = 1, \dots, K$) of the predictors, where the distributed lag effect of a single predictor variable, and of the interaction of two predictor variables are captured by the sums $\sum_{k=0}^{K} f_{2}(p_{t-k}, k)$ and $\sum_{k=0}^{K} f_{3}(o_{t-k}, w_{t-k}, k)$ respectively.

Further examples include @Boente2023, @Du2012, and @Ho2020, who applied semi-parametric additive models to predict housing prices, household gasoline consumption, and ground-level $\text{PM}_{2.5}$ concentrations, respectively. @Ibrahim2023 considered nonparametric additive models to predict census survey response rates. Additionally, @Ravindra2019 provided a comprehensive review of the applications of additive models in environmental data, with a special focus on studies related to air pollution, climate change, and human health.

While nonparametric and semi-parametric additive models have been used in diverse application problems, there are several unresolved issues in their implementation. First, estimating these models in high-dimensional settings is challenging due to the large number of nonparametric components to be estimated. Second, there is noticeable subjectivity in selecting predictor variables (from the available predictors) and identifying which terms should be grouped together to model interactions. In most of the applications discussed above, the choices are based on empirical explorations or domain expertise.

In this paper, we are interested in high-dimensional applications that exhibit complicated interactions among predictors, particularly in the presence of a large number of lagged variables and correlated errors. In such situations, *index models* prove beneficial in improving the flexibility of the broader class of nonparametric additive models [@Radchenko2015], while mitigating the difficulty of estimating a nonparametric component for each individual predictor.

Therefore, we propose to address the above mentioned issues using a ***Sparse Multiple Index*** (SMI) model with automatic variable selection and grouping. This semi-parametric model can be written as
$$
  y_{i} = \beta_{0} + \sum_{j = 1}^{p}g_{j}(\bm{\alpha}_{j}^{T}\bm{x}_{ij}) + \sum_{k = 1}^{d}f_{k}(w_{ik}) + \bm{\theta}^{T}\bm{u}_{i} + \varepsilon_{i}, \quad i = 1, \dots, n,
$$ {#eq-semipara}
where $y_{i}$ is the univariate response, $\beta_{0}$ is the model intercept, $\bm{x}_{ij} \in \mathbb{R}^{l_{j}}$, $j = 1, \dots, p$ are $p$ subsets of predictors entering indices, $\bm{\alpha}_{j}$ is a vector of index coefficients corresponding to the index $h_{ij} = \bm{\alpha}_{j}^{T}\bm{x}_{ij}$, $g_{j}$ is a smooth nonlinear function (possibly estimated by a spline). Note that the model also allows for predictors that do not enter any indices, including covariates $w_{ik}$ that relate to the response through nonlinear functions $f_{k}$, $k = 1, \dots, d$, and linear covariates $\bm{u}_{i}$. Although our focus is on forecasting time series data, the model can be used more widely, and so we have not included any notation specific to time series in the model formulation.

The SMI model subsumes the models discussed above, incorporating fully additive models [@Wood2011;@Wood2017], where each predictor has its own index, and single index models [@Stoker1986;@Hardle1993;@Radchenko2015], where all predictors are included in a single index. The greater generality allows us to address the two issues mentioned earlier. First, the number of parameters to estimate is reduced by combining variables using linear indices, and by grouping predictors into indices to manage the complexity of interactions. In our model formulation, both the number of indices $p$ and the predictor grouping among indices are unknown. We propose algorithmic selection of the predictors to include in each index, thereby reducing the subjectivity in model formulation. We assume that no predictor enters more than one index, i.e., overlapping of predictors among indices is not allowed.

To our knowledge, no previous research has explored objective and principled predictor selection in nonparametric additive index models. Hence, our goal is to develop a methodology for optimal predictor selection and grouping in the context of high-dimensional nonparametric additive index models. Moreover, recent computational advancements have sparked significant interest in using mathematical optimisation to solve statistical problems [@Theusl2020]. This motivated us to develop a variable selection algorithm based on mathematical optimisation techniques.

It is crucial to note that any variable selection methodology naturally renders inferential statistics invalid, since we do not assume that the resulting model obtained through the variable selection procedure represents the true data generating process. Hence, our focus is only on improving forecasts, but not on making inferences on parameter estimates.

The rest of this paper is organised as follows. @sec-SMI presents our proposed *Sparse Multiple Index Model* and describes the algorithm for variable selection and grouping, and the estimation procedure. In @sec-simulation, we demonstrate the functionality and characteristics of the proposed algorithm through a simulation experiment. @sec-application illustrates two empirical applications of the proposed estimation and variable selection methodology, related to forecasting heat exposure related daily mortality and daily solar intensity. Some benchmark comparison methods are briefly introduced in @sec-benchmark. Concluding remarks are given in @sec-conclusion.

# Sparse Multiple Index Model {#sec-SMI}

## Optimisation Problem Formulation

We implement variable selection for the proposed ***Sparse Multiple Index*** (SMI) model (@eq-semipara) by allowing for zero index coefficients for predictors. Suppose we observe $y_1,\dots,y_n$, along with a set of potential predictors, $\bm{x}_1,\dots,\bm{x}_n$, with each vector $\bm{x}_i$ containing $q$ predictors. The optimisation problem we seek to address is of the form below, where the sum of the squared error of the model (@eq-semipara) is minimised together with an $\ell_{0}$ penalty term and an $\ell_{2}$ (ridge) penalty term:
\begin{align}
  & \min_{\beta_{0}, p, \bm{\alpha}, \bm{g}, \bm{f}, \bm{\theta}} \quad \sum_{i = 1}^{n}\Bigg [ y_{i} - \beta_{0} - \sum_{j = 1}^{p}g_{j}(\bm{\alpha}_{j}^{T}\bm{x}_{i}) - \sum_{k = 1}^{d}f_{k}(w_{ik}) - \bm{\theta}^{T}\bm{u}_{i}\Bigg]^{2} \label{eq-smi}\\
  & \hspace*{8cm} + \lambda_{0}\sum_{j = 1}^{p}\sum_{m = 1}^{q}\mathbb{1}(\alpha_{jm} \neq 0) + \lambda_{2}\sum_{j = 1}^{p}\|\bm{\alpha}_{j}\|_2^2 \nonumber \\
  & \text{such that}\quad \sum_{j=1}^p \mathbb{1}(\alpha_{jm} \neq 0) \in \{0,1\} \quad \forall m ,\nonumber
\end{align}
where $\bm{\alpha} = [\bm{\alpha}_{1}^{T}, \dots, \bm{\alpha}_{p}^{T} ]^{T}$, $\bm{g} = \{g_{1}, g_{2}, \dots, g_{p}\}$, $\bm{f} = \{f_{1}, f_{2}, \dots, f_{d}\}$, $\mathbb{1}(\cdot)$ is the indicator function, $\lambda_{0} > 0$ is a tuning parameter that controls the number of selected predictors entering indices, and $\lambda_{2} \ge 0$ is another tuning parameter that controls the strength of the additional shrinkage imposed on the estimated index coefficients. The constraint ensures that every predictor can only have non-zero coefficient in at most one index.

Applying an $\ell_{2}$-penalty in addition to the $\ell_{0}$-penalty is motivated by related literature [@Hazimeh2020; @Mazumder2023; @Hazimeh2023], where it is suggested that the prediction performance of best-subset selection is enhanced by the inclusion of an additional ridge penalty, especially when there is a low signal-to-noise ratio (SNR).

To solve the optimisation problem in Equation \ref{eq-smi}, we present a big-$M$ based ***Mixed Integer Quadratic Programming*** (MIQP) formulation:
$$
\begin{aligned}
  \min_{\beta_{0}, p, \bm{\alpha}, \bm{g}, \bm{f}, \bm{\theta}, \bm{z}} \quad & \sum_{i = 1}^{n}\Bigg [ y_{i} - \beta_{0} - \sum_{j = 1}^{p}{g_{j}(\bm{\alpha}_{j}^{T}\bm{x}_{i})} - \sum_{k = 1}^{d} {f_{k}(w_{ik})} - \bm{\theta}^{T}\bm{u}_{i}\Bigg ]^{2} + \lambda_{0}\sum_{j = 1}^{p}\sum_{m = 1}^{q}z_{jm} + \lambda_{2}\sum_{j = 1}^{p}\sum_{m = 1}^{q} \alpha_{jm}^{2} \\
  \text{s.t.} \quad & |\alpha_{jm}| \le Mz_{jm} \quad \forall j, \forall m, \\
  & \sum_{j = 1}^{p}z_{jm} \le 1 \quad \forall m, \\
  & z_{jm} \in \{0, 1\},
\end{aligned}
$$ {#eq-smi-mip}
where $j = 1, \dots, p$, and $m = 1, \dots, q$. We have introduced binary variables $z_{jm} = \mathbb{1}(\alpha_{jm} \neq 0)$ to indicate in which index (if any) each predictor enters. The pre-specified *big-$M$ parameter* is denoted by $M < \infty$, and it should be sufficiently large. If $\bm{\alpha^{*}}$ is the optimal solution to the problem given in @eq-smi-mip, then the big-$M$ parameter should satisfy $\max \big ( \{|\alpha_{jm}^{*} |\}_{j\in[p],m\in[q]} \big) \le M$. The big-$M$ constraint ensures that $\alpha_{jm}$ is zero if and only if $z_{jm}$ is zero, and if $z_{jm} = 1$, then $|\alpha_{jm}| \le M$. At the same time, the $\ell_{0}$-penalty term influences some of the binary variables $z_{jm}$ to be zero, while the $\ell_{2}$-penalty term enforces additional shrinkage on the estimated coefficients. Together, these components achieve variable selection.

## Estimation Algorithm

We now show how to efficiently find a minimiser for the problem given in @eq-smi-mip. Since the number of indices $p$, the vector of index coefficients $\bm{\alpha}$, and the set of nonparametric functions $\bm{g}$ are all unknown, it is impossible to solve the above MIQP given in @eq-smi-mip directly. Hence, we propose an iterative algorithm to solve the problem.

### Initialising the Index Structure and Index Coefficients {#sec-step1}

We first need to provide a feasible initialisation for the index structure (i.e. the number of indices $p$ and the grouping of predictors among indices) as well as for the index coefficients ($\bm{\alpha}$) of the model.

Based on several experiments, we propose four possible methods for initialising the SMI model as follows.

1.  **PPR: Projection Pursuit Regression Based Initialisation**

    A Projection Pursuit Regression model [@Friedman1981] is a multiple index model, where each index includes all the available predictors. Since the proposed SMI model requires that there are no overlapping indices, it is impossible to use an estimated PPR model directly as a starting model for the algorithm. Thus, we follow the steps presented below to come up with a feasible initialisation for the index structure and the index coefficients.

    a. Scale all the variables of the data set by dividing each variable by its standard deviation (so that it is possible to compare the estimated coefficients among predictors).
    b. Fit a PPR model and obtain estimated index coefficients. (The user can decide the number of initial indices $p^*$ to be estimated; we use $p^* = 5$ in our simulations and applications.)
    c. Calculate a threshold $\tau = 0.1 \times \max(\mathrm{abs}(\text{PPR index coefficients}))$.
    d. Set to zero all coefficients whose absolute values fall below the calculated threshold.
    e. For predictors appearing in multiple indices, assign them to the index with the maximum absolute coefficient and zero out their coefficients in other indices.
    f. After performing the above steps a-e, if any originally estimated index has all zero coefficients, it will be excluded from the model.

    Now, the index structure and the index coefficients obtained through the above steps are considered to be a feasible initialisation for the proposed algorithm. Once the optimal SMI model is obtained through the algorithm, each index coefficient will be back-transformed to the original scale of the respective predictor variable, reversing the scaling effect applied at the beginning.

2.  **Additive: Nonparametric Additive Model Based Initialisation**

    As a fully additive model is a special case of the SMI model, we can set $p=q$ and assign each predictor to its own index.

3. **Linear: Linear Regression Based Initialisation**

    We first regress the response variable on the predictors using a multiple linear regression. Then, we construct a single index (i.e. $p = 1$) using the estimated regression coefficients as the initial index coefficients of the predictors.

4. **Multiple: Picking One From Multiple Initialisations**

    We use multiple random instances of a model (i.e. predictor assignment to indices and initial index coefficients are generated randomly) with a user specified number of indices as initial models, optimise the SMI model for each of them, and pick the initial model that results in the lowest loss for the MIQP problem. The number of random instances of the model to be evaluated is also decided by the user. 
    
Of course, it is also possible for a user to specify an initialisation, based on their own domain expertise or prior knowledge in, initialising the algorithm. In each of the above initialisation options, once the estimate for $\bm{\alpha}$ is obtained, the estimated initial index coefficients for each index are scaled to have unit norm to ensure identifiability.

### Estimating Nonlinear Functions {#sec-step2}

Once we have an estimate for $\bm{\alpha}$, estimating the SMI model is equivalent to estimating a Generalized Additive Model (GAM) as
$$
  y_{i} = \beta_{0} + \sum_{j = 1}^{p}g_{j}(\hat{h}_{ij}) + \sum_{k = 1}^{d}f_{k}(w_{ik}) + \bm{\theta}^{T}\bm{u}_{i} + \varepsilon_{i}, \quad i = 1, \dots, n,
$$
where $y_{i}$ is the response, and $\hat{h}_{ij} = \hat{\bm{\alpha}}_{j}^{T}\bm{x}_{i}$ is the estimated index. The R packages ***mgcv*** [@Wood2011] and ***gam*** [@Hastie2023], for example, can be used to fit GAMs.

### Updating the Index Structure and Index Coefficients {#sec-step3}

We obtain the updated index coefficients $\bm{\alpha}^{\text{new}}$ through a MIQP:
$$
\begin{aligned}
  \min_{\bm{\alpha}^{\text{new}}, \bm{z}^{\text{new}}} & (\bm{\alpha}^{\text{new}} - \bm{\alpha}^{\text{old}})^{T}\bm{V}^{T}\bm{V}(\bm{\alpha}^{\text{new}} - \bm{\alpha}^{\text{old}}) - 2(\bm{\alpha}^{\text{new}} - \bm{\alpha}^{\text{old}})^{T}\bm{V}^{T}\bm{r} + \lambda_{0}\sum_{j = 1}^{p}\sum_{m = 1}^{q}z_{jm}^{\text{new}} + \lambda_{2}\sum_{j = 1}^{p}\sum_{m = 1}^{q}(\alpha_{jm}^{new})^2 \\
  \text{s.t. } & |\alpha_{jm}^{\text{new}}| \le Mz_{jm}^{\text{new}} \quad \forall j, \forall m,\\
  & z_{jm}^{\text{new}} \in \{0, 1\}, \\
  & \sum_{j = 1}^{p}z_{jm}^{\text{new}} \le 1 \quad \forall m,
\end{aligned}
$$ {#eq-smi-update}
where $j = 1, \dots, p$, $m = 1, \dots, q$, $\bm{\alpha}^{\text{old}}$ is the current value of $\bm{\alpha}$, $z_{jm}^{\text{new}}$ are the updated set of binary variables to be estimated, and $\bm{V}$ is the matrix of partial derivatives of the right hand side of @eq-semipara with respect to $\bm{\alpha}_{j}$. The $i^{th}$ row of $\bm{V}$ contains $[ \bm{v}_{i1}, \dots, \bm{v}_{ip}]$, where $\bm{v}_{ij} = \bm{x}_{i}g_{j}'(h_{ij})$. The current residual vector, which contains $r_{i} = y_{i} - \beta_{0} - \sum_{j = 1}^{p}g_{j}\big((\bm{\alpha}_{j}^{\text{old}})^T\bm{x}_{i}\big)$, is denoted by $\bm{r}$. It is important to note that the additional covariates $w_{ik}$ and $\bm{u}_{i}$ are not required to update $\bm{\alpha}_{j}$, because they are constants with respect to $\bm{\alpha}_{j}$, and thus they disappear from $\bm{V}$.

Similar to the explanation given by @Masselot2022, the MIQP objective function in @eq-smi-update ignores the Hessian (the matrix of second derivatives of @eq-semipara, with respect to $\bm{\alpha}_{j}$), and considers only the matrix of first derivatives, which is a quasi-Newton step  [@Peng2022]. Therefore, the $\bm{\alpha}$ updating step given in @eq-smi-update is assured to be in a descent direction.

After obtaining $\bm{\alpha}^{\text{new}}$, if any of the estimated individual index coefficient vectors $\bm{\alpha}_{j}^{\text{new}}$ contains all zeros, they will be dropped from the model. Then we scale each estimated index coefficient vector $\hat{\bm{\alpha}}_{j} = \bm{\alpha}_{j}^{\text{new}}$ to have a unit norm.

Next, the algorithm alternates between updating the index coefficients $\bm{\alpha}$ and estimating the nonlinear functions $\bm{g}$ until it meets one of the three criteria: (i) the reduction ratio of the objective (loss) function value in @eq-smi-mip, calculated between consecutive iterations, reaches a pre-specified convergence tolerance; (ii) the loss increases consecutively for three iterations; or (iii) the maximum number of iterations is reached. The selection of convergence tolerance and maximum iterations depends on the specific problem or data.

Finally, we consider adjusting the index structure of the model to exploit any potential benefits in terms of further minimising the loss function in @eq-smi-mip. As indices can be automatically reduced by dropping zero indices in each optimisation iteration, this step focuses on potential index additions to the current model. Specifically, we consider adding a new index to the current model by identifying dropped predictors. If applicable, a new index is constructed with all these dropped predictors, and the alternating updating process from the previous step is repeated. This step continues until one of these termination criteria is met: (i) the number of indices reaches $q$, selecting the final model as output; (ii) loss increases after the increment, selecting the previous iteration model as the final SMI model; or (iii) the solution maintains the same number of indices as the previous iteration, and the absolute difference of index coefficients between two successive iterations is not larger than a pre-specified tolerance, choosing the model with the smaller loss as the final SMI model in this case.

To obtain an estimated model with the best possible forecasting accuracy, it is important to select appropriate values for the non-negative penalty parameters $\lambda_{0}$ and $\lambda_{2}$. One possible way to do this is to estimate the model over a grid of possible values for $\lambda_{0}$ and $\lambda_{2}$, and then select the combination that yields the lowest loss function value. Moreover, it is also crucial to choose a suitable value for the big-$M$ parameter, as the strength of the MIP formulation depends on the choice of a good upper bound [@Bertsimas2016]. According to @Hazimeh2023, several methods have been used to select $M$ in practice. For more details on estimating $M$ in a linear regression setting, refer to @Bertsimas2016.

The following algorithm summarises the key steps of the SMI Modelling algorithm. \newline

### Algorithm 1: SMI Modelling Algorithm {-}

1. Initialise $p$, the predictor grouping among indices, and obtain the initial estimate of $\bm{\alpha}$ using one of the options in @sec-step1. Then scale each $\hat{\bm{\alpha}}_{j}$, $j=1,\dots,p$, to have a unit norm.
2. Estimate $g_{j}$, $j=1,\dots,p$, using a GAM taking $y_{i}$ as the response and $\hat{\bm{\alpha}}_{j}^{T}\bm{x}_{i}$ as predictors.
3. Update $\bm{\alpha}$ through the MIQP in @eq-smi-update, and scale each $\hat{\bm{\alpha}}_{j}$ to have a unit norm.
4. Iterate steps 2 and 3 until convergence, loss increases for three consecutive iterations, or reaching the maximum iterations.
5. If there are no dropped predictors, stop. Otherwise, include a new index consisting of dropped predictors, and repeat step 4.
6. Increase $p$ by one in each iteration of step 5 until meeting one of the termination criteria below.
   - The number of indices in the iteration reaches $q$; select the final fitted model as output.
   - Loss increases after the increment; select the previous iteration model as the final SMI model.
   - The solution maintains the same number of indices as the previous iteration, and the absolute difference of index coefficients between two successive iterations is not larger than a pre-specified tolerance; select the model with a smaller loss as the final SMI model.

Throughout the experiments in the paper, we use $M = 10$, a convergence tolerance of $0.001$, a maximum of $50$ iterations in step 4 of Algorithm 1; and a convergence tolerance of $0.001$ for coefficients in step 6 of Algorithm 1.

# Simulation Experiment {#sec-simulation}

This section presents the results of a simulation experiment designed to demonstrate the performance and characteristics of the proposed SMI Modelling algorithm. In particular, we investigate how the estimated SMI model varies depending on the initialisation used.

## Data Generation {#sec-datagen}

**Generating predictor variables:**

First, we generate two time series, each of length 1205: $x_{t,0}$ from a uniform distribution on the interval $[0, 1]$, and $z_{t,0}$ from a normal distribution $N(5, 4)$. Next, we construct lagged series of both $x_{t,0}$ and $z_{t,0}$, where $x_{t,i}$ denotes the $i^{th}$ lag of $x_{t,0}$, and $z_{t,i}$ denotes the $i^{th}$ lag of $z_{t,0}$. Then $\bm{x}_t = \{x_{t,0}, x_{t,1}, \dots, x_{t,5}\}$, and $\bm{z}_t = \{z_{t,0}, z_{t,1}, \dots, z_{t,5}\}$ are taken as predictors in the simulation experiment.

**Generating response variables:**

We generate two response variables $y_{t}$ and $w_{t}$, using two different index structures and a normally distributed white noise component with two different variances as follows:

-   Low noise level - $N(\mu = 0, \sigma^2 = 0.01)$:\
      $y_{t} = (0.9*x_{t,0} + 0.6*x_{1,t} + 0.45*x_{3,t})^3 + \epsilon, \quad \epsilon\sim N(0, 0.01)$\
      $w_{t} = (0.9*x_{t,0} + 0.6*x_{1,t} + 0.45*x_{3,t})^3 + (0.35*x_{2,t} + 0.7*x_{5,t})^2 + \epsilon, \quad \epsilon\sim N(0, 0.01)$

-   High noise level - $N(\mu = 0, \sigma^2 = 0.25)$:\
      $y_{t} = (0.9*x_{t,0} + 0.6*x_{1,t} + 0.45*x_{3,t})^3 + \epsilon, \quad \epsilon\sim N(0, 0.25)$\
      $w_{t} = (0.9*x_{t,0} + 0.6*x_{1,t} + 0.45*x_{3,t})^3 + (0.35*x_{2,t} + 0.7*x_{5,t})^2 + \epsilon, \quad \epsilon\sim N(0, 0.25)$

Hence, the response $y_{t}$ is constructed using a single index consisting of the predictor variables $x_{t,0}, x_{t,1}$, and $x_{t,3}$, whereas the other response $w_{t}$ is constructed using two indices, where the first index consists of the predictors $x_{t,0}, x_{t,1}$, and $x_{t,3}$, and the second index consists of $x_{t,2}$ and $x_{t,5}$. Neither the variable $x_{t,4}$ nor any of the $z$ variables are used in generating $y_{t}$ and $w_{t}$.

Once the data set is generated, the first five observations are discarded due to the missing values introduced by lagged variables, leaving a data set with 1200 observations. We use the first 1000 observations as the training set, while the remaining 200 observations are kept aside as the test set for evaluating the estimated models.

## Experiment Setup {#sec-exp}

We estimate SMI models through the proposed algorithm for each of the two response variables, using three different sets of predictors as inputs. Our aim is to assess the algorithm's capability to correctly pick the relevant predictor variables (and drop the irrelevant predictors), and to estimate the index structure of the true model.

The three different sets of predictors considered are as follows:

1. All $\bm{x}$ variables (denoted as "all $\bm{x}$");
2. All $\bm{x}$ variables and all $\bm{z}$ variables (denoted as "all $\bm{x}$ + all $\bm{z}$");
3. The first three $\bm{x}$ variables (i.e. $x_{0,t}, x_{1,t}$ and $x_{2,t}$) and all $\bm{z}$ variables (denoted as "some $\bm{x}$ + all $\bm{z}$").

We apply the proposed SMI Modelling algorithm with each of the above predictor combinations, for both variations of the responses concerning the noise level. Moreover, we consider every initialisation options discussed in @sec-step1, for each of the two responses.

## Results {#sec-sim-results}

We summarise the results of the simulation experiment in @tbl-simulation. In the columns, we indicate the index structure (i.e. the predictor grouping among indices) estimated by the proposed algorithm under each of the initialisation options, i.e., "PPR", "Additive", "Linear", and "Multiple". The numbers stated (in parentheses) below the index structures are the test MSE values of the corresponding estimated models. This is detailed for each combination explored, considering response, input predictors, and noise levels.

Our experiments indicated that, for this simple example, different values of penalty parameters have a negligible impact on the estimated models. Thus, we did not perform any tuning for the penalty parameters $\lambda_{0}$ and $\lambda_{2}$ in the simulation experiment. The default values $\lambda_{0} = 1$ and $\lambda_{2} = 1$ were used in estimating all the models presented in @tbl-simulation.

```{r}
#| label: tbl-simulation
#| tbl-cap: "Simulation experiment results: Index structures and test MSEs of the estimated SMI models for each combination of response, input predictors, and noise levels."
#| tbl-pos: "!h"
results_sim <- readr::read_csv(here::here("paper/results/simulation_table_final_modified.csv"))
# Fix notation
results_sim <- results_sim |>
  mutate(
    Model = stringr::str_replace(Model, "y_\\{1\\}", "y_{t}"),
    Model = stringr::str_replace(Model, "y_\\{2\\}", "w_{t}"),
  ) |>
  mutate(across(c("PPR","Additive","Linear","Multiple"),
                ~stringr::str_replace_all(., "x_\\{([0-9])\\}", "x_{\\1,t}"))) |>
  mutate(across(c("PPR","Additive","Linear","Multiple"),
                ~stringr::str_replace_all(., "z_\\{([0-9])\\}", "z_{\\1,t}"))) 
kable(results_sim,
  format = "latex",
  booktabs = TRUE,
  escape = FALSE,
  linesep = c("", "", "\\addlinespace"),
  col.names = c("Model", "Predictors", "PPR", "Additive", "Linear", "Multiple")
) |>
  pack_rows(
    index = c("Low noise level" = 12, "High noise level" = 12),
    latex_gap_space = "0.6em"
  ) |>
  row_spec(row = 6, extra_latex_after = "[1.6em]") |>
  row_spec(row = 18, extra_latex_after = "[1.6em]") |>
  kable_styling(latex_options = c("repeat_header", "scale_down")) |>
  row_spec(0, bold = TRUE)
```

At a low noise level, in both cases of "all $\bm{x}$" and "all $\bm{x}$ + all $\bm{z}$", all initialisations enable the algorithm to estimate the correct index structure for both $y_{t}$ and $w_{t}$, with an exception in the "Linear" option for $w_{t}$. The "Linear" option for $w_{t}$ selects the correct variables, but fails to identify the two-index structure. This suggests that initialising the algorithm with a higher number of indices might be more effective than with a lower number. In the case of "some $\bm{x}$ + all $\bm{z}$", for both $y_{t}$ and $w_{t}$, the models estimated under all initialisations include some noise variables. This indicates that when the available predictors are insufficient to capture the data signal, the algorithm might select irrelevant variables to make up for the missing signal.

When the fitted models are evaluated for $y_{t}$, in both cases of "all $\bm{x}$" and "all $\bm{x}$ + all $\bm{z}$", all initialisations result in a test set Mean Squared Error (MSE) of $\approx 0.01$, which corresponds to the variance of the true model error. This confirms the accuracy with which the SMI Modelling algorithm estimates the index structure for $y_{t}$. For $w_{t}$, all the estimated models result in a test set MSE of $\approx 0.16$. This is an interesting result as the test set MSE of an estimated model with incorrect index structure, but with correct predictors ("Linear") is similar to the models with correct index structure ("PPR", "Additive", and "Multiple"). This suggests that the selection of the predictor variables is more important than determining the index structure of the model in this case. For both $y_{t}$ and $w_{t}$, in the case of "some $\bm{x}$ + all $\bm{z}$", MSE on the test set increases in comparison to the above cases, probably due to the inclusion of the noise variables.

Moreover, in contrast to $y_{t}$, the test set MSE values for $w_{t}$ are higher than the variance of the true model error. Intuitively, the complexity of the model $w_{t}$ is higher than $y_{t}$, where the total estimation error of two nonlinear functions (corresponding to the two indices) for $w_{t}$, might be higher than the error of estimating a single nonlinear function for $y_{t}$.

As expected, the SMI Modelling algorithm's accuracy in estimating the index structure is generally lower with the high noise level than with the low noise level. At a high noise level, most of the estimated models have selected irrelevant variables for both $y_{t}$ and $w_{t}$. In both the cases of "all $\bm{x}$" and "all $\bm{x}$ + all $\bm{z}$", all the models estimated for $y_{t}$ (except for the "Additive" option in the "all $\bm{x}$" case) result in a test set MSE of $\approx 0.23$, which is slightly lower than the variance of the true model error. This occurs irrespective of the inclusion of irrelevant variables in "PPR" option for the "all $\bm{x}$" case, and in the "Additive" and "Multiple" options for the "all $\bm{x}$ + all $\bm{z}$" case. This suggests over-fitting when there is a low signal-to-noise ratio in the data. The same result is observed for $w_{t}$, where, irrespective of the different index structures and predictor choices, the estimated models in the above two predictor combinations produce similar MSE values on the test set.

Similar to the previous case with a low noise level, when only a part of $\bm{x}$ variables are provided, the test set MSE values increase for both $y_{t}$ and $w_{t}$, where the estimated models for $w_{t}$ produce higher test MSE values compared to those for $y_{t}$.

It is worth mentioning here that in real-world forecasting problems, the true data generating process (DGP) is unknown, and we do not expect an estimated model to precisely capture the true DGP. Therefore, as long as the estimated model demonstrates good forecasting accuracy, the exact index structure of the model is less important.

Finally, the simulation study indicates that the choice of the initialisation depends on the specific data and application. Thus, users are encouraged to follow a trial-and-error procedure to determine the most suitable initial model for a given application.

# Empirical Applications {#sec-application}

## Forecasting Daily Mortality {#sec-mortality}

We apply the SMI Modelling algorithm to a data set used in @Masselot2022, to forecast daily mortality based on heat exposure. Studying the effects of various environmental exposures such as weather related variables, pollutants and man-made environmental conditions on human health, is of significant importance in environmental epidemiology.

### Description of the Data

For this analysis, we consider daily mortality and heat exposure data for the Metropolitan Area of Montreal, Québec, Canada, from 1990 to 2014, for the months June, July, and August (i.e. summer). The daily all-cause mortality data were obtained from the National Institute of Public Health, Québec, while *DayMet*, a $1\text{km} \times 1\text{km}$ grid data set [@Thornton2021], was used to extract daily temperature and humidity data.

@fig-deaths shows the time plots of daily deaths during the summer for the years from 1990 to 1993. The series for each of the four years are presented separately in a faceted grid for visual clarity.

```{r}
#| label: fig-deaths
#| fig-cap: Daily mortality in summer in Montreal, Canada from 1990 to 1993.
dataHeat <- readRDS(here::here("data/Heat_Corrected.rds"))
dataHeat |>
  mutate(Date = as.POSIXct(Date)) |>
  filter(Date <= "1993-08-31") |>
  ggplot(aes(x = Date, y = Death_lag_000)) +
  geom_line(colour = "grey40") +
  geom_point(colour = "grey40", size = 0.5) +
  facet_wrap(vars(Year), scales = "free_x", ncol = 1, strip.position = "left") +
  scale_x_datetime(date_breaks = "1 month") +
  labs(x = "Date", y = "Number of Deaths", title = "") +
  theme_bw()
```

Maximum temperature, minimum temperature, and vapour pressure (to represent the level of humidity) are considered as predictors in this empirical study. The number of daily deaths is plotted against each of these predictors in @fig-Tmax, where we can observe that the relationships between these predictors and the response are slightly nonlinear.

```{r}
#| label: fig-Tmax
#| fig-cap: Daily mortality in summer (from 1990 to 2014) plotted against maximum temperature, minimum temperature and vapor pressure.
#| fig-height: 6
#| fig-width: 9
p1 <- dataHeat |>
  ggplot(aes(x = Tmax_lag_000, y = Death_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.15, size = 0.9) +
  xlim(c(0, 35)) +
  labs(
    x = "Maximum Temperature (Degrees Celsius)",
    y = "Number of Deaths",
    title = ""
  ) +
  theme_bw()
p2 <- dataHeat |>
  ggplot(aes(x = Tmin_lag_000, y = Death_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.15) +
  xlim(c(0, 35)) +
  labs(
    x = "Minimum Temperature (Degrees Celsius)",
    y = "Number of Deaths",
    title = ""
  ) +
  theme_bw()
p3 <- dataHeat |>
  ggplot(aes(x = Vp_lag_000, y = Death_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.15) +
  labs(x = "Vapour Pressure", y = "Number of Deaths", title = "") +
  theme_bw()
patchwork::wrap_plots(p1,p2,p3, ncol=2, nrow=2)
```

\pagebreak[3]

### Predictors Considered

#### 1) Daily deaths lags:

Fourteen lags of the daily deaths itself are used as predictors to incorporate the serial correlations presented in the data into the modelling process.

#### 2) Current maximum/minimum temperatures and lags:

In addition to current maximum and minimum temperatures, the temperature measurements up to 14 days prior are considered as predictors in the forecasting model. This accounts for the cumulative impact of both current and recent past temperatures on a person's heat exposure.

#### 3) Current vapour pressure and lags:

Similarly, the current value and 14 lags of vapour pressure are considered as predictors, as a proxy for the level of humidity.

#### 4) Calendar effects:

Finally, a couple of calendar variables (*day of the season (DOS)* and *Year*) are incorporated into the model to capture annual trend and seasonality, which is a common practice in environmental epidemiology.

### Modelling Framework

Death lags, maximum temperature lags, minimum temperature lags, and vapour pressure lags are predictors that may enter indices. The two calendar variables, *DOS* and *Year*, are included in the model as separate nonparametric components that do not enter any of the indices. Hence, the relevant SMI model can be written as
$$
  \textbf{Deaths} = \beta_{0} + \sum_{j = 1}^{p}{g_{j}(\bm{X}\bm{\alpha}_{j})} + f_{1}(\textbf{DOS}) + f_{2}(\textbf{Year})+ \bm{\varepsilon},
$$
where

- $\textbf{Deaths}$ is the vector containing daily deaths observations;
- $\beta_{0}$ is the model intercept;
- $p$ is the unknown number of indices to be estimated via the proposed algorithm;
- $\bm{X}$ is a matrix containing the $q=59$ predictor variables that may enter indices (i.e. death lags, maximum temperature lags, minimum temperature lags, and vapour pressure lags);
- $\bm{\alpha}_{j}$, $j = 1, \dots, p$ are the index coefficient vectors, each of length $q$;
- $g_{1}, \dots,g_p$, $f_{1}$, and $f_{2}$ are unknown nonparametric functions; and
- $\bm{\varepsilon}$ is the error term.

The data from 1990 to 2012 are used as the training set to estimate the model, while the data from the three summer months of year 2013 are kept aside as a validation set. This validation set is used to perform the penalty parameter tuning of the SMI models. Here, once the tuning for the two penalty parameters is completed, the models are re-fitted for the data set combining training and validation sets. The data of year 2014 are used as the test set for evaluating forecasting performance.

The forecasting accuracy on the test set is evaluated using MSE and Mean Absolute Error (MAE). We assume that the future values of the maximum/minimum temperatures and vapour pressure are known to use in the forecasting model; thus it is a post hoc analysis.

### Benchmark Methods {#sec-benchmark}

In addition to our proposed SMI model, we also evaluate three benchmark models for comparison purposes.

The first benchmark is a nonparametric additive model formulated through ***Backward Elimination***, as proposed by @FH2012. The process starts with all variables included in an additive model, and variables are progressively omitted until the optimal model is obtained based on the validation set. Once the optimal model is obtained, the final model is re-fitted for the data set combining training and validation sets.

The second benchmark is a ***Group-wise Additive Index Model (GAIM)***, which can be written in the form
$$
  y_{i} = \sum_{j = 1}^{p} g_{j}(\bm{\alpha}_{j}^{T}\bm{x}_{ij}) + \varepsilon_{i},
$$
where $y_{i}$ is the univariate response, $\bm{x}_{ij} \in \mathbb{R}^{l{j}}$, $j = 1, \dots, p$ are pre-specified non-overlapping subsets of $\bm{x}_{i}$, and $\bm{\alpha}_j$ are the corresponding index coefficients, $g_{j}$ is an unknown (possibly nonlinear) component function, and $\varepsilon_{i}$ is the random error, which is independent of $\bm{x}_{i}$ [@Wang2015; @Masselot2022]. For this model, death lags, maximum temperature lags, minimum temperature lags, and vapour pressure lags are intuitively categorised into four separate groups, with an index estimated for each group.

The third benchmark is a ***Projection Pursuit Regression (PPR)*** model [@Friedman1981] given by
$$
  y_{i} = \sum_{j=1}^{p} {g_{j}(\bm{\alpha}_{j}^{T}\bm{x}_{i})} + \varepsilon_{i},
$$
where $y_{i}$ is the response, $\bm{x}_{i}$ is the $q$-dimensional predictor vector, $\bm{\alpha}_{j} = ( \alpha_{j1}, \dots, \alpha_{jp} )^{T}$, $j = 1, \dots, p$ are $q$-dimensional projection vectors (or vectors of "index coefficients"), $g_{j}$'s are unknown nonlinear functions, and $\varepsilon_{i}$ is the random error. The number of indices in the PPR model was taken as four, matching the number of indices estimated by the GAIM.

Here, no parameter tuning or variable/model selection is involved in the two benchmark models *GAIM* and *PPR*. Hence, these models are directly estimated on the data set combining the original training and validation sets to ensure legitimate comparison of forecasting performance among models. 

### Results

We estimated SMI models for the mortality data using three different initialisation options: "PPR", "Additive" and "Linear", for comparison purposes. We tuned the penalty parameters $\lambda_{0}$ and $\lambda_{2}$ over ranges of integers from 1 to 12, and 0 to 12 respectively, based on validation set MSE. Here, a greedy search is used instead of a grid search to reduce computational time. (We introduce the notation ***SMI Model (a, b)*** to indicate that the penalty parameter combination used in an estimated SMI model is $(\lambda_{0} = a, \lambda_{2} = b)$.)

The penalty parameter combination $(\lambda_{0} = 5, \lambda_{2} = 12)$ was selected for the model fitted with "PPR" initialisation. The estimated model, ***SMI Model (5, 12) - PPR***, resulted in seven indices without dropping any of the index variables. The optimal penalty parameter combination for the model initiated with "Additive" was $(\lambda_{0} = 1, \lambda_{2} = 0)$, resulting in the ***SMI Model (1, 0) - Additive***, equivalent to a nonparametric additive model (no index variables or indices were dropped). The model estimated with "Linear" initialisation selected $(\lambda_{0} = 6, \lambda_{2} = 11)$ (***SMI Model (6, 11) - Linear***), and resulted in two indices, without dropping any of the index variables.

We evaluated forecasting errors of the estimated models using two subsets of the original test set:

1. ***Test Set 1:*** original test set spanning three months (June, July and August 2014); and
2. ***Test Set 2:*** a test set covering one month (June 2014).

The MSE and MAE values on the two different test sets for the estimated SMI models along with all benchmark methods considered are presented in @tbl-heat. We observe that the SMI model estimated with "PPR" initialisation, ***SMI Model (5, 12) - PPR***, shows the best forecasting performance on both test sets, compared to the other two estimated SMI models.

```{r}
#| label: tbl-heat
#| tbl-cap: Daily mortality forecasting - Out-of-sample point forecast results.
#| tbl-pos: "!hb"
results_heat <- readr::read_csv("results/heat_results_correct.csv")
kable(results_heat,
    format = "latex",
    booktabs = TRUE,
    digits = 3,
    escape = FALSE,
    linesep = "",
    col.names = c("Model", "Predictors", "Indices", "MSE", "MAE", "MSE", "MAE")
  ) |>
  add_header_above(c("", "", "", "Test Set 1" = 2, "Test Set 2" = 2), align = "c") |>
  kable_styling(latex_options = c("repeat_header")) |>
  row_spec(0, align = "c") |>
  column_spec(4, bold = if_else(results_heat$MSE1 == min(results_heat$MSE1), TRUE, FALSE)) |>
  column_spec(5, bold = if_else(results_heat$MAE1 == min(results_heat$MAE1), TRUE, FALSE)) |>
  column_spec(6, bold = if_else(results_heat$MSE2 == min(results_heat$MSE2), TRUE, FALSE)) |>
  column_spec(7, bold = if_else(results_heat$MAE2 == min(results_heat$MAE2), TRUE, FALSE))
```

@tbl-heat also shows that ***SMI Model (5, 12) - PPR*** outperforms all three benchmark models in terms of forecasting accuracy, for both *Test Set 1* and *Test Set 2*. However, the SMI models estimated using "Additive" or "Linear" initialisations have inferior forecasting performance compared to GAIM and PPR models. 
<!-- The actual number of deaths and the predicted values from the ***SMI Model (5, 12) - PPR*** and benchmark models on *Test Set 2* are plotted in @fig-heatPred for further comparison. -->

```{r}
#| label: fig-heatPred
#| include: false
#| fig-cap: Actual number of deaths vs. predicted number of deaths from "SMI Model (5, 12) - PPR" and benchmark models for Test Set 2.
#| fig-height: 3
#| fig-width: 7
readr::read_csv("results/heat_predictions_correct.csv") |>
  select(-SMImodel_Additive, -SMImodel_Linear) |>
  rename(
    `SMI Model (5, 12) - PPR` = SMImodel_PPR,
    `Backward Elimination` = Backward
  ) |>
  tidyr::pivot_longer(Actual:GAIM, names_to = "Series", values_to = "Deaths") |>
  ggplot(aes(x = Date, y = Deaths, colour = Series)) +
  geom_line() +
  scale_x_date(date_breaks = "7 days") +
  labs(x = "Date", y = "Number of Deaths") +
  ggtitle("Actual vs. Predicted Number of Deaths") +
  scale_colour_manual(name = "Series", values = c(
    "Actual" = "grey",
    "SMI Model (5, 12) - PPR" = "#D55E00",
    "PPR" = "#0072B2",
    "Backward Elimination" = "#009E73",
    "GAIM" = "#CC79A7"
  )) +
  theme(
    legend.position = "bottom",
    legend.box = "vertical"
  ) +
  theme_bw()
```

## Forecasting Daily Solar Intensity {#sec-solar}

Next, we utilise the SMI Modelling algorithm to forecast daily solar intensity, using other weather conditions.

### Description of the Data

We use solar intensity and other weather variables measured at the Davis weather station in Amherst, Massachusetts, obtained from the *UMass Trace Repository* [@Umass2023]. The data was recorded every five minutes from 24 February 2006 to 27 February 2013, using sensors for measuring temperature, wind chill, humidity, dew point, wind speed, wind direction, rain, pressure, solar intensity, and UV. We converted the five-minute data to daily data by averaging each variable over each day.

@fig-solar shows the time plot of daily solar intensity for the entire period, which clearly depicts the annual seasonality in the data. The gaps show days for which the observations were missing; these were excluded from the analysis.

```{r}
#| label: fig-solar
#| fig-height: 3.5
#| fig-cap: Daily solar intensity in Amherst, Massachusetts, from February 2006 to February 2013.
dataSolar <- readRDS(here::here("data/solar_data_withFourier.rds")) |>
  as_tsibble(index = Date) |>
  fill_gaps()
dataSolar |>
  ggplot(aes(x = Date, y = Solar_lag_000)) +
  geom_line(colour = "grey40") +
  scale_x_date(date_breaks = "1 year") +
  labs(title = "", y = "Solar Intensity (Watts per square metre)") +
  theme_bw()
```

In @fig-preds, the daily solar intensity is plotted against each of the predictors: temperature, dew point, wind, rain and humidity. We can observe that the relationships between these predictors and the response are nonlinear.

```{r}
#| label: fig-preds
#| fig-height: 8
#| fig-cap: Daily solar intensity against other weather variables.
p1 <- dataSolar |>
  ggplot(aes(x = Temp_lag_000, y = Solar_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.5, size = 0.3) +
  xlim(c(-25, 90)) +
  xlab("Temperature (Degrees Fahrenheit)") +
  ylab("Solar Intensity") +
  ggtitle("Solar Intensity against Temperature") +
  theme(
    axis.title = element_text(size = 8),
    plot.title = element_text(size = 9)
  ) +
  theme_bw()

p2 <- dataSolar |>
  ggplot(aes(x = Dewpt_lag_000, y = Solar_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.5, size = 0.3) +
  xlim(c(-25, 90)) +
  xlab("Dew Point (Degrees Fahrenheit)") +
  ylab("Solar Intensity") +
  ggtitle("Solar Intensity against Dew Point") +
  theme(
    axis.title = element_text(size = 8),
    plot.title = element_text(size = 9)
  ) +
  theme_bw()

p3 <- dataSolar |>
  ggplot(aes(x = Wind_lag_000, y = Solar_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.5, size = 0.3) +
  xlab("Wind Speed (Miles per hour)") +
  ylab("Solar Intensity") +
  ggtitle("Solar Intensity against Wind Speed") +
  theme(
    axis.title = element_text(size = 8),
    plot.title = element_text(size = 9)
  ) +
  theme_bw()

p4 <- dataSolar |>
  ggplot(aes(x = Rain_lag_000, y = Solar_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.5, size = 0.3) +
  xlab("Rain (Inches)") +
  ylab("Solar Intensity") +
  ggtitle("Solar Intensity against Rain") +
  theme(
    axis.title = element_text(size = 8),
    plot.title = element_text(size = 9)
  ) +
  theme_bw()

p5 <- dataSolar |>
  ggplot(aes(x = Humid_lag_000, y = Solar_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.5, size = 0.3) +
  xlab("Humidity (Percentage)") +
  ylab("Solar Intensity") +
  ggtitle("Solar Intensity against Humidity") +
  theme(
    axis.title = element_text(size = 8),
    plot.title = element_text(size = 9)
  ) +
  theme_bw()

grid.arrange(p1, p2, p3, p4, p5, nrow = 3, ncol = 2)
```

### Predictors Considered

#### 1) Solar intensity lags:

Three lags of the daily solar intensity itself are used as predictors to incorporate the serial correlations presented in the data into the modelling process.

#### 2) Current weather variables and lags:

In addition to current temperature, dew point, wind speed, rain and humidity, the measurements of the three previous days for each of the these weather variables are also included as predictors in the forecasting model.

#### 3) Calendar effects:

Finally, a calendar variable, *day of the year (DOY)* is incorporated into the model as a smooth function using Fourier terms to capture annual seasonality, and also to control the autocorrelation in residuals.

### Modelling Framework

The lags of solar intensity, and the lags of weather variables are considered as predictors that may enter indices. The Fourier terms capturing the day of the year effect are included into the model as linear variables (so that they are not part of the indices).

We considered the number of pairs of Fourier terms ($K$) from $K = 1$ to $K = 10$, and used the SMI model with "Linear" initialisation to determine the number of pairs that best captures the day of the year effect, based on the validation set MSE. (That is, multiple SMI models were fitted using different numbers of pairs Fourier terms, and the number of pairs of Fourier terms corresponding to the model that resulted in the lowest validation set MSE was selected.) The SMI model (with "Linear" initialisation) estimated with $K = 8$ resulted in the lowest validation set MSE, and hence $K = 8$ was taken as the number of pairs of Fourier terms in estimating all the SMI models and benchmark models.

Hence, the relevant SMI model can be written as
$$
  \textbf{Solar} = \beta_{0} + \sum_{j = 1}^{p}{g_{j}(\bm{X}\bm{\alpha}_{j})} + \sum_{k = 1}^{8}(\theta_{k}\textbf{DOY}\_\textbf{S}_{\bm{k}} + \delta_{k}\textbf{DOY}\_\textbf{C}_{\bm{k}}) + \bm{\varepsilon},
$$
where

- $\textbf{Solar}$ is the vector containing daily observations of solar intensity;
- $\beta_{0}$ is the model intercept;
- $p$ is the unknown number of indices to be estimated via the algorithm;
- $\bm{X}$ is a matrix containing the $q=23$ predictor variables that may enter indices (i.e. solar intensity, temperature, dew point, wind speed, rain and humidity lags);
- $\bm{\alpha}_{j}$, $j = 1, \dots, p$ are the index coefficient vectors, each of length $q$;
- $g_{1}, \dots, g_{p}$ are unknown nonparametric functions;
- $\textbf{DOY}\_\textbf{S}_{\bm{k}}$ and $\textbf{DOY}\_\textbf{C}_{\bm{k}}$, $k = 1, \dots, 8$ are the sine and cosine terms of the first eight pairs of Fourier terms corresponding to the variable $\textbf{DOY}$ respectively (seasonal period = 365.25);
- $\theta_{k}$ and $\delta_{k}$, $k = 1, \dots, 8$ are the coefficients of $\textbf{DOY}\_\textbf{S}_{\bm{k}}$ and $\textbf{DOY}\_\textbf{C}_{\bm{k}}$ respectively; and
- $\bm{\varepsilon}$ is the error term.

The data from February 2006 to October 2012 are used as the training set to estimate the model, while the data from November and December 2012 are kept aside as a validation set. This validation set is used to perform the penalty parameter tuning of the SMI models as well as selecting the best number of pairs of Fourier terms to be used for the variable *DOY* in this application. Once the tuning for the two penalty parameters and the selection of the Fourier terms are completed, the models are re-fitted for the entire data set combining training and validation sets. The data of January and February 2013 comprise the test set to evaluate the forecasting performance of the estimated models.

The forecasting accuracy of the estimated models on the test set is evaluated using MSE and MAE. We assumed that the future values of the weather variables are known; thus it is a post hoc analysis.

### Results

We estimated SMI models for the solar intensity data using three different initialisation options: "PPR", "Additive" and "Linear". We also tuned the penalty parameters $\lambda_{0}$ and $\lambda_{2}$, over ranges of integers from 1 to 12, and 0 to 12 respectively.

The penalty parameter combination $(\lambda_{0} = 1, \lambda_{2} = 0)$ was selected for the model fitted with "PPR" initialisation. The estimated model, ***SMI Model (1, 0) - PPR***, resulted in four indices without dropping any of the index variables. The optimal penalty parameter combination for the model estimated taking "Additive" model as the starting point was $(\lambda_{0} = 6, \lambda_{2} = 0)$. The estimated SMI model did not drop any index variables or indices, and thus the final model, ***SMI Model (6, 0) - Additive***, is equivalent to a semi-parametric additive model. The model estimated with "Linear" initialisation also selected $(\lambda_{0} = 1, \lambda_{2} = 0)$. Unlike the above models, this SMI Model dropped all index variables and resulted in null indices, and hence, the final model, ***SMI Model (1, 0) - Linear***, is just a linear model with the sixteen linear variables $\textbf{DOY}\_\textbf{S}_{\bm{k}}$ and $\textbf{DOY}\_\textbf{C}_{\bm{k}}$, $k = 1, \dots, 8$. Notice that the all three SMI models have $\lambda_{2} = 0$, indicating that the models have omitted the $\ell_{2}$-penalty in the estimation process.

@tbl-solar presents the MSE and MAE values for the estimated SMI models on the test set. The results indicate that the SMI model estimated with "PPR" initialisation, ***SMI Model (1, 0) - PPR***, shows the best forecasting performance among the three estimated SMI models.

We also present forecasting errors of the three benchmark models in @tbl-solar, to compare with the estimated SMI models. Here, the GAIM is fitted by grouping the lags of each weather variable into distinct group, resulting in six indices. The number of indices of the PPR model was taken as six, matching the number of indices estimated by the GAIM. Note that here, the calendar variable *DOY* was excluded when estimating the PPR model because including separate linear terms is not feasible in a PPR model.

```{r}
#| label: tbl-solar
#| tbl-cap: Daily solar intensity forecasting - Out-of-sample point forecast results.
results_solar <- readr::read_csv("results/solar_results_fourier8.csv")
kable(results_solar,
  format = "latex",
  booktabs = TRUE,
  digits = 3,
  linesep = "",
  escape = FALSE,
  col.names = c("Model", "Predictors", "Indices", "MSE", "MAE")
) |>
  add_header_above(c("", "", "", "Test Set" = 2), align = "c") |>
  kable_styling(latex_options = c("repeat_header")) |>
  row_spec(0, align = "c") |>
  column_spec(4, bold = if_else(results_solar$MSE == min(results_solar$MSE), TRUE, FALSE)) |>
  column_spec(5, bold = if_else(results_solar$MAE == min(results_solar$MAE), TRUE, FALSE))
```

@tbl-solar shows that the forecasting errors of ***SMI Model (1, 0) - PPR*** is lower than the backward elimination and GAIM models. However, the ***SMI Model (1, 0) - PPR*** is unable to outperform the PPR model, which has resulted in the best forecasting accuracy in this case.

Here, it is worth considering the differences between the SMI model and the PPR model that shows superior forecasting performance. When estimating a PPR model, both the number of indices and the predictors within each index (each index includes all provided predictors that are entering indices) are pre-determined. In contrast, the SMI model takes a more general and objective approach, where the number of indices as well as predictors within each index are automatically determined through the proposed algorithm. Thus, the SMI model faces a more challenging estimation task due to the limited prior information provided regarding the model structure.

<!-- The actual solar intensity and the predicted values from the  ***SMI Model (1, 0) - PPR*** and benchmark models are plotted in @fig-solarPred for further comparison. -->

```{r}
#| label: fig-solarPred
#| include: false
#| fig-cap: Actual solar intensity vs. predicted solar intensity from "SMI Model (1, 0) - PPR" and benchmark models.
SolarPreds <- readr::read_csv("results/solar_predictions_fourier8.csv") |>
  rename(
    `SMI Model (1, 0) - PPR` = SMImodel_PPR,
    `Backward Elimination` = Backward
  ) |>
  select(-SMImodel_Additive, -SMImodel_Linear) |>
  tidyr::pivot_longer(Actual:GAIM, names_to = "Series", values_to = "Intensity")
SolarPreds |>
  ggplot(aes(x = Date, y = Intensity, colour = Series)) +
  geom_line() +
  scale_x_date(date_breaks = "7 days") +
  labs(
    x = "Date", y = "Solar Intensity (Watts per square metre)",
    title = "Actual vs. Predicted Solar Intensity"
  ) +
  scale_colour_manual(name = "Series", values = c(
    "Actual" = "grey",
    "SMI Model (1, 0) - PPR" = "#D55E00",
    "PPR" = "#0072B2",
    "Backward Elimination" = "#009E73",
    "GAIM" = "#CC79A7"
  )) +
  theme(
    legend.position = "bottom",
    legend.box = "vertical"
  ) +
  theme_bw()
```

## Software

These two empirical applications were performed using the R statistical software [@Rcore]. We developed the ***smimodel*** package for R, available at <https://github.com/nuwani-palihawadana/smimodel>, to implement the proposed SMI modelling algorithm. All the data and code to reproduce the experiments are made available at <https://github.com/nuwani-palihawadana/smimodel_paper>.

We used the commercial MIP solver ***Gurobi*** [@gurobi2023] to solve the MIQPs related to the proposed SMI Modelling algorithm, through the ***Gurobi plug-in*** [ROI.plugin.gurobi, @Schwendinger2023] available from the ***R Optimization Infrastructure*** [ROI, @Hornik2023; @Theusl2020] package. The GAMs were fitted using the R package ***mgcv*** [@mgcv;@Wood2011].

# Conclusions and Further Research {#sec-conclusion}

In this paper, we have presented a novel algorithm for estimating a nonparametric/semi-parametric additive index model with optimal predictor selection and predictor grouping, which we refer to as Sparse Multiple Index (SMI) Model. The SMI Modelling algorithm is an iterative procedure that is developed based on mixed integer programming to solve an $\ell_{0}$-regularised nonlinear least squares optimisation problem with linear constraints.

The proposed SMI Modelling algorithm has a number of key features: 1) It performs automatic selection of both the number of indices and the predictor grouping when estimating the nonparametric additive index model. Users need to input the set of predictors entering indices and a starting model (index structure and a set of index coefficients) to initialise the algorithm. 2) It performs automatic variable selection, which is particularly beneficial in high-dimensional settings. This feature contributes to an objective and principled estimation, reducing subjectivity across different users. 3) It is capable of estimating a wide spectrum of models, from single index models (one index) to additive models (number of indices equals the number of predictors entering indices). Hence, the SMI Modelling algorithm is a more general estimation tool for nonparametric additive models. 4) It provides the flexibility to include separate nonlinear and linear predictors in the model that are not entering any indices, allowing the estimation of semi-parametric additive models.

We demonstrated the performance of the proposed algorithm through a simulation study and two empirical applications. Due to the limited input information provided to the algorithm, the estimation of a SMI model is a challenging problem.

In both of the empirical applications presented, the SMI model estimated with "PPR" initialisation resulted in the best forecasting performance out of the three different SMI models estimated, indicating that "PPR" initialisation might be a more viable option. However, these two examples are insufficient to establish a universally applicable initialisation option for the SMI model across various scenarios. Hence, as mentioned in @sec-simulation, we encourage users to follow a trial-and-error procedure to identify the most effective initialisation option for their specific application.

Since the difficulty of specifying an initialisation that works in general is a limitation of the proposed algorithm, an interesting future research problem would be to explore the potential for determining a generalised initialisation for the SMI Modelling algorithm that will work well across various applications.

This study should be viewed as a first attempt to develop a more objective methodology for variable selection and model estimation in the broader class of nonparametric additive models for forecasting. An important future research problem is, therefore, to assess the performance of the proposed SMI Modelling algorithm across various data sets with diverse properties, identifying scenarios where it outperforms other benchmark methods.

The MIQP in the algorithm is somewhat analogous to the *best subset selection* method frequently used in least squares problems. Thus, another limitation of the proposed algorithm is the increase in computational time as the number of predictors and the number of indices increase. Therefore, it would be an interesting research exercise to obtain further insights regarding the algorithm to see what improvements can be made to the algorithm design to reduce the computational cost in a high-dimensional context.

# Acknowledgements {-}

We thank Professor Louise Ryan for useful discussions during the initial stage of the project, and for her valuable comments and feedback on this research work.

This research is partially supported by the Monash eResearch Centre through the use of the MonARCH (Monash Advanced Research Computing Hybrid) HPC Cluster, and by the Australian Research Council Industrial Transformation Training Centre in Optimisation Technologies, Integrated Methodologies, and Applications (OPTIMA), Project ID IC200100009.
