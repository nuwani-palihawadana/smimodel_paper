---
title: "Sparse Multiple Index Models for High-dimensional Nonparametric Forecasting"
author:
- name: Nuwani Palihawadana
  affiliations:
    - name: Monash University
      department: Department of Econometrics & Business Statistics
      city: Clayton VIC
      country: Australia
      postal-code: 3800
  email: nuwani.kodikarapalihawadana@monash.edu
  corresponding: true
- name: Rob J Hyndman
  affiliations:
    - name: Monash University
      department: Department of Econometrics & Business Statistics
      city: Clayton VIC
      country: Australia
      postal-code: 3800
  email: rob.hyndman@monash.edu
- name: Xiaoqian&nbsp;Wang
  affiliations:
    - name: Monash University
      department: Department of Econometrics & Business Statistics
      city: Clayton VIC
      country: Australia
      postal-code: 3800
  email: xiaoqian.wang@monash.edu
abstract: Forecasting often involves high-dimensional predictors, which have nonlinear relationships with the outcome of interest. Nonparametric additive index models can capture these relationships, while addressing the curse of dimensionality. This paper introduces a new algorithm, ***S***parse ***M***ultiple ***I***ndex (***SMI***) ***Modelling***, tailored for estimating high-dimensional nonparametric additive index models, while limiting the number of parameters to estimate, by optimising predictor selection and predictor grouping. The SMI Modelling algorithm uses an iterative approach based on mixed integer programming to solve an $\ell_{0}$-regularised nonlinear least squares optimisation problem with linear constraints. We demonstrate the performance of the proposed algorithm through a simulation study, along with two empirical applications to forecast heat-related daily mortality and daily solar intensity.
keywords: [Additive index models, Variable selection, Dimension reduction, Predictor grouping, Mixed integer programming]
bibliography: references.bib
wpnumber: no/yr
jelcodes: C10,C14,C22
blind: false
cover: true
keep-tex: true
include-in-header: 
  - text: |
      \usepackage{todonotes}
format:
  wp-pdf:
    knitr:
      opts_chunk:
        dev: "CairoPDF"
execute:
  echo: false
  warning: false
  message: false
  cache: true
---

```{r}
#| label: load
#| cache: false
# Load all required packages
library(tsibble)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(knitr)
library(kableExtra)
options(knitr.kable.NA = '')
theme_set(theme_get() + theme(text = element_text(family = "Source Sans Pro")))
```

# Introduction {#sec-introduction}

Forecasts are often contingent on a very long history of predictors, which are nonlinearly related to the variable of interest. For example, when forecasting half-hourly electricity demand, it is common to use at least a week of historical half-hourly temperatures and other weather observations [@HF2010]. The relationships between the lagged temperatures and electricity demand are nonlinear (due to both heating and cooling effects), and involve complex interactions due to thermal inertia in buildings [@FH2012].
Similarly, when forecasting bore levels, rainfall data from up to thousand days earlier can impact the result [@Peterson2014;@Bakker2019;@Rajaee2019] due to the complex nonlinear flow dynamics of rainfall into aquifers.

These examples suggest a possible nonlinear "*transfer function*" model of the form
$$
 y_t = f(\bm{x}_{t}, \bm{x}_{t-1}, \dots,\bm{x}_{t-p}, y_{t-1},\dots,y_{t-k}) + \varepsilon_{t},
$$ {#eq-transferfun}
where $y_{t}$ is the observation of the response variable at time $t$, $\bm{x}_{t}$ is a vector of predictors at time $t$, and $\varepsilon_{t}$ is an iid random error. By including lagged values of $y_{t}$ along with the lagged predictors, we allow for any serial correlation in the data.

The form of $f$ is typically nonlinear, and involves complicated interactions with a high value of $p$ (and possibly also large $k$). It is infeasible to estimate $f$ in high-dimensional settings (where $p$ is large) due to the curse of dimensionality [@Bellman57; @Stone82]. Instead, we normally impose some form of additivity constraint, and ignore interactions of more than 2 or 3 variables. There are also usually many ad hoc model choices in selecting the appropriate predictors to include.

For example, @FH2012 proposed a ***semi-parametric additive model*** to obtain short-term forecasts of the half-hourly electricity demand for power systems in the Australian National Electricity Market. In this model, $f$ is assumed to be fully additive, and is used to capture the effects of recent predictor values on the demand. The main objective behind the use of this proposed semi-parametric model is to allow nonparametric components in a regression-based modelling framework with serially correlated errors. The model fitted for each half-hourly period ($q$) can be written as
$$
 \log(y_{t,q}) = h_{q}(t) + f_{q}(\bm{w}_{1,t},\bm{w}_{2,t}) + \sum_{j=1}^k a_{q,j}(y_{t-j}) + \varepsilon_{t},
$$ {#eq-FH}
where the response variable is the logarithm of electricity demand at time $t$ during period $q$. The term $h_{q}(t)$ models several calendar effects as linear or smooth terms. Temperature effects are modelled using the nonparametric component $f_{q}(\bm{w}_{1,t},\bm{w}_{2,t})$, where $\bm{w}_{i,t} = [w_{i,t},\dots,w_{i,t-p}]'$ is a vector of lagged temperatures at site $i$. The terms $a_{q,j}(y_{t-j})$ capture the lagged effects of the response. It is important to notice here that the error term $\varepsilon_{t}$ is serially uncorrelated within each half-hourly model, because the serial correlation is eliminated by the inclusion of lagged responses in the model. However, some correlation may still exist between residuals from various half-hourly models [@FH2012].

Similarly, a ***distributed lag model*** was proposed by @Wood2017 to forecast daily death rates in Chicago using measurements of several air pollutants. The response variable is modelled via a sum of smooth functions of lagged predictor variables, which is quite similar to the semi-parametric additive model used by @FH2012. However, unlike in @FH2012, @Wood2017 suggested allowing the smooth functions for lags of the same covariate to vary smoothly over lags, preventing large differences in estimated effects between adjacent lags. Thus, the model is of the form
$$
 \log(y_{t}) = f_{1}(t) + \sum_{k=0}^{K} f_{2}(p_{t-k}, k) + \sum_{k=0}^{K} f_{3}(o_{t-k}, w_{t-k}, k),
$$
where $y_{t}$ is the death rate at day $t$, $f_{1}$ is a nonparametric term to capture the *time* effect, and $p_t$, $o_t$, and $w_t$ are various predictor variables. The model incorporates the current value ($k = 0$) and several lagged values ($k = 1, \dots, K$) of the predictors, where the distributed lag effect of a single predictor variable, and of an interaction of two predictor variables are captured by the sum of $\sum_{k=0}^{K} f_{2}(p_{t-k}, k)$ and $\sum_{k=0}^{K} f_{3}(o_{t-k}, w_{t-k}, k)$ respectively. The smooth functions $f_{2}$ and $f_{3}$ are proposed to be estimated using tensor product smooths.

Further examples include @Ho2020, who used semi-parametric additive models to estimate ground-level $\text{PM}_{2.5}$ concentrations in Taiwan, while nonparametric additive models were utilised by @Ibrahim2021 for predicting census survey response rates. @Ravindra2019 provides a comprehensive review of the applications of additive models in environmental data, with a special focus on air pollution, climate change, and human health related studies.

In this paper, we are interested in high-dimensional applications that exhibit complicated interactions among predictors, particularly in the presence of a large number of lagged variables, and correlated errors. In such situations, *index models* prove beneficial in improving the flexibility of the broader class of nonparametric additive models [@Radchenko2015], while mitigating the difficulty of estimating a nonparametric component for each individual predictor.

While such models have been used to address problems from diverse application areas, there are several unresolved issues in using them. In this paper, we attempt to address two of those issues. First, the estimation of the model is challenging in high-dimensional settings due to the large number of nonparametric components to be estimated. Second, there is a noticeable subjectivity in selecting predictor variables (from the available predictors) for the model, and in identifying which terms to include together to model interactions. In most of the applications discussed above, the choices were based on empirical explorations or domain expertise.

We propose to address these issues using a Sparse Multiple Index (SMI) model with automatic variable selection. This semiparametric model can be written as
$$
  y_{i} = \beta_{0} + \sum_{j = 1}^{p}g_{j}(\bm{\alpha}_{j}^{T}\bm{x}_{ij}) + \sum_{k = 1}^{d}f_{k}(w_{ik}) + \bm{\theta}^{T}\bm{u}_{i} + \varepsilon_{i}, \quad i = 1, \dots, n,
$$ {#eq-semipara}
where $y_{i}$ is the univariate response, $\beta_{0}$ is the model intercept, $\bm{x}_{ij} \in \mathbb{R}^{l_{j}}$, $j = 1, \dots, p$ are $p$ subsets of all the predictors entering indices, $\bm{\alpha}_{j}$ is a vector of index coefficients corresponding to the index $h_{ij} = \bm{\alpha}_{j}^{T}\bm{x}_{ij}$, $g_{j}$ is a smooth nonlinear function (possibly estimated by a spline). Note that we also allow for the inclusion of predictors that do not enter any of the indices, including covariates $w_{ik}$ that relate to the response through the nonlinear functions $f_{k}$, $k = 1, \dots, d$, and linear covariates denoted by $\bm{u}_{i}$. Although our interest is in forecasting time series data, the model can be used more widely, and so we have not included any notation specific to time series in the model formulation.

This model subsumes the models discussed above, and includes fully additive models [@Wood2011;@Wood2017], where each predictor is in its own index, and single index models [@Stoker1986;@Hardle1993;@Radchenko2015], where all predictors are in a single index. The greater generality allows us to address the two issues mentioned earlier. First, the number of parameters to estimate is reduced by combining variables using linear indices, and by grouping predictors into indices to limit the order and form of interactions allowed. In our model formulation, the number of indices $p$ is unknown, and the predictor grouping among indices is unknown. We propose algorithmic selection of the predictors to include in each indices, thereby reducing the subjectivity in model formulation. We assume that no predictor enters more than one index (i.e. overlapping of predictors among indices is not allowed).

To our knowledge, no previous research has been done to explore how predictor choices can be made more objective and principled in nonparametric additive index models. Hence, our goal was to develop a methodology for optimal predictor selection in the context of high-dimensional nonparametric additive index models. Moreover, due to computational advancements in the field, the use of mathematical optimisation concepts in solving statistical problems has gained a lot of recent interest [@Theusl2020]. This motivated us to develop a variable selection algorithm based on mathematical optimisation techniques.

It is crucial to point out that any variable selection methodology naturally renders inferential statistics invalid, since we do not assume that the resulting model obtained through the variable selection procedure represents the true data generating process. Hence, our focus is only on improving forecasts, but not on making inferences on the resulting parameter estimates.

The rest of this paper is organised as follows. @sec-SMI presents our proposed *Sparse Multiple Index Model* and describes the variable selection algorithm and estimation procedure. Some benchmark comparison methods are briefly introduced in @sec-benchmark. In @sec-simulation, we demonstrate the functionality and the characteristics of the proposed algorithm through a simulation experiment. @sec-application illustrates two empirical applications of the proposed estimation and variable selection methodology, related to forecasting heat exposure related daily mortality and daily solar intensity. Concluding remarks are given in @sec-conclusion.

# Sparse Multiple Index Model {#sec-SMI}

## Optimisation Problem Formulation

We implement variable selection for the proposed semi-parametric additive index (SMI) model (@eq-semipara) by allowing for zero index coefficients for predictors. Suppose we observe $y_1,\dots,y_n$, along with a set of potential predictors, $\bm{x}_1,\dots,\bm{x}_n$, with each vector $\bm{x}_i$ containing $q$ predictors. The optimisation problem we seek to address is of the form below, where the sum of the squared error of the model (@eq-semipara) is minimised together with an $\ell_{0}$ penalty term and an $\ell_{2}$ (ridge) penalty term:
\begin{align}
  & \min_{\beta_{0}, p, \bm{\alpha}, \bm{g}, \bm{f}, \bm{\theta}} \quad \sum_{i = 1}^{n}\Bigg [ y_{i} - \beta_{0} - \sum_{j = 1}^{p}g_{j}(\bm{\alpha}_{j}^{T}\bm{x}_{i}) - \sum_{k = 1}^{d}f_{k}(w_{ik}) - \bm{\theta}^{T}\bm{u}_{i}\Bigg]^{2} \label{eq-smi}\\
  & \hspace*{8cm} + \lambda_{0}\sum_{j = 1}^{p}\sum_{m = 1}^{q}\mathbb{1}(\alpha_{jm} \neq 0) + \lambda_{2}\sum_{j = 1}^{p}\|\bm{\alpha}_{j}\|_2^2 \nonumber \\
  & \text{such that}\quad \sum_{j=1}^p \mathbb{1}(\alpha_{jm} \neq 0) \in \{0,1\} \quad \forall m ,\nonumber
\end{align}
where $\bm{\alpha} = [\bm{\alpha}_{1}^{T}, \dots, \bm{\alpha}_{p}^{T} ]^{T}$, $\bm{g} = \{g_{1}, g_{2}, \dots, g_{p}\}$, $\bm{f} = \{f_{1}, f_{2}, \dots, f_{d}\}$, $\mathbb{1}(\cdot)$ is the indicator function, $\lambda_{0} > 0$ is a tuning parameter that controls the number of selected predictors entering indices, and $\lambda_{2} \ge 0$ is another tuning parameter that controls the strength of the additional shrinkage imposed on the estimated index coefficients. The condition ensures that a predictor can only have non-zero coefficient in at most one index.

Applying an $\ell_{2}$-penalty in addition to the $\ell_{0}$-penalty is motivated by related literature [@Hazimeh2020; @Mazumder2022; @Hazimeh2023], where it is suggested that the prediction performance of best-subset selection is enhanced by the inclusion of an additional ridge penalty, especially when there is a low signal-to-noise ratio (SNR).

To solve the optimisation problem in Equation \ref{eq-smi}, we present a big-$M$ based ***Mixed Integer Quadratic Programming*** (MIQP) formulation:
$$
\begin{aligned}
  \min_{\beta_{0}, p, \bm{\alpha}, \bm{g}, \bm{f}, \bm{\theta}, \bm{z}} \quad & \sum_{i = 1}^{n}\Bigg [ y_{i} - \beta_{0} - \sum_{j = 1}^{p}{g_{j}(\bm{\alpha}_{j}^{T}\bm{x}_{i})} - \sum_{k = 1}^{d} {f_{k}(w_{ik})} - \bm{\theta}^{T}\bm{u}_{i}\Bigg ]^{2} + \lambda_{0}\sum_{j = 1}^{p}\sum_{m = 1}^{q}z_{jm} + \lambda_{2}\sum_{j = 1}^{p}\sum_{m = 1}^{q} \alpha_{jm}^{2} \\
  \text{s.t.} \quad & |\alpha_{jm}| \le Mz_{jm} \quad \forall j, \forall m, \\
  & \sum_{j = 1}^{p}z_{jm} \le 1 \quad \forall m, \\
  & z_{jm} \in \{0, 1\},
\end{aligned}
$$ {#eq-smi-mip}
where $\bm{z} = (\bm{z}_{11}, \dots, \bm{z}_{pm})^{T}$, $j = 1, \dots, p$, and $m = 1, \dots, q$. In other words, we have introduced binary variables $z_{jm} = \mathbb{1}(\alpha_{jm} \neq 0)$ to indicate in which index (if any) each predictor enters.

The pre-specified *big-$M$ parameter* is denoted by $M < \infty$, and it should be sufficiently large. If $\bm{\alpha^{*}}$ is the optimal solution to the problem given in @eq-smi-mip, then the big-$M$ parameter should satisfy $\max \big ( |\alpha_{jm}^{*} | \big) \le M$. The big-$M$ constraints ensure that $\alpha_{jm}$ is zero if and only if $z_{jm}$ is zero, and if $z_{jm} = 1$, then $|\alpha_{jm}| \le M$. At the same time, the $\ell_{0}$-penalty term $\lambda_{0}\sum_{j = 1}^{p}\sum_{m = 1}^{q}z_{jm}$ influences some of the binary variables $z_{jm}$ to be zero, while the $\ell_{2}$-penalty term $\lambda_{2}\sum_{j = 1}^{p}\sum_{m = 1}^{q}\alpha_{jm}^{2}$ enforces additional shrinkage on the estimated coefficients. Together, these components perform variable selection.

## Estimation Algorithm

We now show how to efficiently find a minimiser for the problem given in @eq-smi-mip. Since the number of indices $p$, the vector of index coefficients $\bm{\alpha}$, and the set of nonparametric functions $\bm{g}$ are all unknown, it is impossible to solve the above MIQP given in @eq-smi-mip directly. Hence, we propose an iterative algorithm to solve the problem.

### Initialising the Index Structure and Index Coefficients {#sec-step1}

In order to start solving the MIQP given in @eq-smi-mip, we first need to provide a feasible initialisation for the index structure (i.e. the number of indices $p$ and the grouping of predictors among indices) as well as for the index coefficients ($\bm{\alpha}$) of the model.

Based on several experiments, we propose three alternative methods for initialising the SMI Model as follows.

1.  **PPR: Projection Pursuit Regression Based Initialisation**

    A Projection Pursuit Regression model [@Friedman1981] is a multiple index model, where each index includes all the available predictors. Since the SMI Model requires that there are no overlapping indices, it is impossible to use an estimated PPR model directly as a starting model for the algorithm. Thus, we follow the steps presented below to come up with a feasible initialisation for the index structure and the index coefficients.

    a. Scale all the variables of the data set by dividing each variable by its standard deviation (so that it is possible to compare the estimated coefficients among predictors).
    b. Fit a PPR model and obtain estimated index coefficients. (The user can decide the number of initial indices $p^*$ to be estimated; we use $p^* = 5$ in our simulations and applications.)
    c. Calculate a threshold $\tau = 0.1 \times \max(\text{PPR coefficients})$.
    d. Set to zero all coefficients that fall below the calculated threshold.
    e. For predictors appearing in multiple indices, assign them to the index with the maximum coefficient and zero out their coefficients in other indices.
    f. After performing the above steps a-e, if any originally estimated index has all zero coefficients, it will be excluded from the model.

    Now, the index structure and the index coefficients obtained through the above steps are considered to be a feasible initialisation for the proposed algorithm. Once the optimal SMI Model is obtained through the algorithm, each index coefficient will be back-transformed to the original scale of the respective predictor variable, reversing the scaling effect applied at the beginning.

2.  **Additive: Nonparametric Additive Model Based Initialisation**

    As a fully additive model is a special case of the SMI Model, we can set $p=q$ and assign each predictor to its own index.

3. **Linear: Linear Regression Based Initialisation**

    We first regress the response variable on the predictors using a multiple linear regression. Then, we construct a single index (i.e. $p = 1$) using the estimated regression coefficients as the index coefficients of the predictors.

The final optimised SMI Model may change depending on the initialisation provided to the algorithm. Hence, we also considered using several different models as initialisations, optimise the SMI Model for each of them, and pick the initial model that results in the lowest loss for the MIQP problem. In our simulations and applications, this is denoted as **Multiple**.

Of course, it is also possible for a user to specify an initialisation, based on their own domain expertise or prior knowledge in initialising the algorithm.

In each of the above initialisation options, once the estimate for $\bm{\alpha}$ is obtained, the estimated initial index coefficients for each index are scaled to have unit norm to ensure identifiability.

### Estimating Nonlinear Functions {#sec-step2}

Once we have an estimate for $\bm{\alpha}$, estimating the SMI Model is equivalent to estimating a GAM as
$$
  y_{i} = \beta_{0} + \sum_{j = 1}^{p}g_{j}(\hat{h}_{ij}) + \sum_{k = 1}^{d}f_{k}(w_{ik}) + \bm{\theta}^{T}\bm{u}_{i} + \varepsilon_{i}, \quad i = 1, \dots, n,
$$
where $y_{i}$ is the response, and $\hat{h}_{ij} = \hat{\bm{\alpha}}_{j}^{T}\bm{x}_{i}$ is the estimated index. The R packages ***mgcv*** [@Wood2011] and ***gam*** [@Hastie2023], for example, can be used to fit GAMs.

### Updating the Index Structure and Index Coefficients {#sec-step3}

We obtain the updated index coefficients $\bm{\alpha}^{\text{new}}$ through a MIQP:
$$
\begin{aligned}
  \min_{\bm{\alpha}^{\text{new}}, \bm{z}^{\text{new}}} & (\bm{\alpha}^{\text{new}} - \bm{\alpha}^{\text{old}})^{T}\bm{V}^{T}\bm{V}(\bm{\alpha}^{\text{new}} - \bm{\alpha}^{\text{old}}) - 2(\bm{\alpha}^{\text{new}} - \bm{\alpha}^{\text{old}})^{T}\bm{V}^{T}\bm{r} + \lambda_{0}\sum_{j = 1}^{p}\sum_{m = 1}^{q}z_{jm}^{\text{new}} + \lambda_{2}\sum_{j = 1}^{p}\sum_{m = 1}^{q}\alpha_{jm}^{(new)2} \\
  \text{s.t. } & |\alpha_{jm}^{\text{new}}| \le Mz_{jm}^{\text{new}} \quad \forall j, \forall m,\\
  & z_{jm}^{\text{new}} \in \{0, 1\}, \\
  & \sum_{j = 1}^{p}z_{jm}^{\text{new}} \le 1 \quad \forall m,
\end{aligned}
$$ {#eq-smi-update}
where $j = 1, \dots, p$, $m = 1, \dots, q$, $\bm{\alpha}^{\text{old}}$ is the current value of $\bm{\alpha}$, $z_{jm}^{\text{new}}$ are the updated set of binary variables to be estimated, and $\bm{V}$ is the matrix of partial derivatives of the right hand side of @eq-semipara with respect to $\bm{\alpha}_{j}$. The $i^{th}$ line of $\bm{V}$ contains $[ \bm{v}_{i1}, \dots, \bm{v}_{ip}]$, where $\bm{v}_{ij} = \bm{x}_{i}g_{j}'(h_{ij})$. The current residual vector, which contains $r_{i} = y_{i} - \beta_{0} - \sum_{j = 1}^{p}g_{j}\big((\bm{\alpha}_{j}^{\text{old}})^T\bm{x}_{i}\big)$, is denoted by $\bm{r}$. It is important to note that the additional covariates $w_{ik}$ and $\bm{u}_{i}$ are not required to update $\bm{\alpha}_{j}$, because they are constants with respect to $\bm{\alpha}_{j}$, and thus they disappear from $\bm{V}$.

Similar to the explanation given by @Masselot2022, the MIQP objective function in @eq-smi-update ignores the Hessian (the matrix of second derivatives of @eq-semipara, with respect to $\bm{\alpha}_{j}$), and considers only the matrix of first derivatives, which is a quasi-Newton step  [@Peng2022]. Therefore, the $\bm{\alpha}$ updating step given in @eq-smi-update is assured to be in a descent direction.

When $\bm{\alpha}^{\text{new}}$ is obtained, if any of the estimated individual index coefficient vectors $\bm{\alpha}_{j}^{\text{new}}$ contains all zeros, they will be dropped from the model. Once the new estimate $\bm{\alpha}^{\text{new}}$ is obtained, we scale each estimated index coefficient vector $\hat{\bm{\alpha}}_{j} = \bm{\alpha}_{j}^{\text{new}}$ to have unit norm.

The algorithm alternates updating the index coefficients $\bm{\alpha}$ and estimating the nonlinear functions $\bm{g}$ until meeting one of the three criteria: (i) the reduction ratio of the objective (loss) function value in @eq-smi-mip, calculated between consecutive iterations, reaches a pre-specified convergence tolerance; (ii) the loss increases consecutively for three iterations; or (iii) the maximum number of iterations is reached. The selection of convergence tolerance and maximum iterations depends on the specific problem or data. In the empirical applications in @sec-application, we used a convergence tolerance of $0.001$ and a maximum of $50$ iterations, stopping at the first criterion reached.

Next, we consider changing the index structure of the model to exploit any benefits in terms of further minimising the loss function in @eq-smi-mip. As indices can be automatically reduced by dropping zero indices in each optimisation iteration, this step focuses on potential index additions to the current model. Specifically, we consider adding a new index to the current model by identifying dropped predictors. If applicable, a new index is constructed with these dropped predictors, and the alternating updating process in the previous step is repeated. This step continues until one of these termination criteria is met: (i) the number of indices reaches $q$, selecting the final model as output; (ii) loss increases after the increment, selecting the previous iteration model as the final SMI model; or (iii) the solution maintains the same number of indices as the previous iteration, and the absolute difference of index coefficients between two successive iterations is not larger than a pre-specified tolerance, choosing the model with the smaller loss as the final SMI model.

To obtain an estimated model with the best possible forecasting accuracy, it is important to select appropriate values for the non-negative penalty parameters $\lambda_{0}$ and $\lambda_{2}$. One possible way to do this is to estimate the model over a grid of possible values for $\lambda_{0}$ and $\lambda_{2}$, and then select the combination that yields the lowest loss function value. Moreover, it is also crucial to choose a suitable value for the big-$M$ parameter, as the strength of the MIP formulation depends on the choice of a good lower bound [@Bertsimas2016]. According to @Hazimeh2023, several methods have been used to select $M$ in practice. For a description on estimating $M$ in a linear regression setting, refer to @Bertsimas2016.

The following algorithm summarises the key steps of the SMI Modelling algorithm. \newline

### Algorithm 1: SMI Modelling Algorithm {-}

1. Initialise $p$, the predictor grouping among indices, and obtain $\bm{\alpha}$ using one of the options in @sec-step1. Then scale each $\hat{\bm{\alpha}}_{j}$, $j=1,\dots,p$, to have unit norm.
2. Estimate $g_{j}$, $j=1,\dots,p$, using a GAM taking $y_{i}$ as the response and $\hat{\bm{\alpha}}_{j}^{T}\bm{x}_{i}$ as predictors.
3. Update $\bm{\alpha}$ through the MIQP in @eq-smi-update, and scale each $\hat{\bm{\alpha}}_{j}$ to have unit norm.
4. Iterate steps 2 and 3 until convergence, loss increase for three consecutive iterations, or reaching the maximum iterations.
5. If there are no dropped predictors, stop. Otherwise include a new index consisting of dropped predictors, and proceed to step 4.
6. Increase $p$ by one in each iteration of step 5 until meeting one of the termination criteria below.
   - The number of indices in the iteration reaches $q$; select the final fitted model as output.
   - Loss increases after the increment; select previous iteration model as the final SMI model.
   - The solution maintains the same number of indices as the previous iteration, and the absolute difference of index coefficients between two successive iterations is not larger than a pre-specified tolerance; select the model with smaller loss as the final SMI model.

Throughout the experiments in the paper, we use $M = 10$, a convergence tolerance of $0.001$, and a maximum of $50$ iterations in step 4 of Algorithm 1, and a convergence tolerance of $0.001$ for coefficients in step 6 of Algorithm 1.

# Simulation Experiment {#sec-simulation}

This section presents the results of a simulation experiment designed to demonstrate the performance and characteristics of the proposed SMI Modelling algorithm. In particular, we investigate how the estimated SMI Model varies depending on the initialisation used.

## Data Generation {#sec-datagen}

**Generating predictor variables:**

First, we generate two iid time series each of length 1205: $x_{0}$ from a uniform distribution on the interval $[0, 1]$, and $z_{0}$ from a normal distribution $N(5, 4)$. Next, we construct lagged series of both $x_{0}$ and $z_{0}$, where $x_i$ denotes the $i^{th}$ lag of $x_{0}$, and $z_i$ denotes the $i^{th}$ lag of $z_{0}$. Then $\bm{x} = \{x_{0}, x_{1}, \dots, x_{5}\}$, and $\bm{z} = \{z_{0}, z_{1}, \dots, z_{5}\}$) were taken as predictors in the simulation experiment.

**Generating response variables:**

We generated two response variables $y_{1}$ and $y_{2}$, with two different index structures, and added a random normal noise component with two different strengths as follows:

-   Low noise level - $N(\mu = 0, \sigma = 0.1)$:\
      $y_{1} = (0.9*x_{0} + 0.6*x_{1} + 0.45*x_{3})^3 + \epsilon, \quad \epsilon\sim N(0, 0.01)$\
      $y_{2} = (0.9*x_{0} + 0.6*x_{1} + 0.45*x_{3})^3 + (0.35*x_{2} + 0.7*x_{5})^2 + \epsilon, \quad \epsilon\sim N(0, 0.01)$

-   High noise level - $N(\mu = 0, \sigma = 0.5)$:\
      $y_{1} = (0.9*x_{0} + 0.6*x_{1} + 0.45*x_{3})^3 + \epsilon, \quad \epsilon\sim N(0, 0.25)$\
      $y_{2} = (0.9*x_{0} + 0.6*x_{1} + 0.45*x_{3})^3 + (0.35*x_{2} + 0.7*x_{5})^2 + \epsilon, \quad \epsilon\sim N(0, 0.25)$

Hence, the response $y_{1}$ is constructed using a single index consisting of the predictor variables $x_{0}, x_{1}$, and $x_{3}$, whereas the other response $y_{2}$ is constructed using two indices, where the first index consists of the predictors $x_{0}, x_{1}$, and $x_{3}$, and the second index consists of $x_{2}$ and $x_{5}$. Neither the variable $x_{4}$ nor any of the $z$ variables were used in generating $y_{1}$ and $y_{2}$.

Once the data set is generated, the first five observations are discarded due to the missing values introduced by lagged variables, leaving a data set of 1200 observations. We use the first 1000 observations as the training set, while the remaining 200 observations are kept aside as the test set for evaluating the estimated models.

## Experiment Setup {#sec-exp}

We estimated SMI Models through the proposed algorithm for each of the two response variables, using three different sets of predictors as inputs. Our aim was to assess the algorithm's capability to correctly pick the relevant predictor variables (and drop the irrelevant predictors), and to estimate the index structure of the true model.

The three different sets of predictors considered are as follows:

1. All $\bm{x}$ variables (denoted as all $\bm{x}$);
2. All $\bm{x}$ variables and all $\bm{z}$ variables (denoted as all $\bm{x}$ + all $\bm{z}$);
3. The first three $\bm{x}$ variables (i.e. $x_{0}, x_{1}$ and $x_{2}$) and all $\bm{z}$ variables (denoted as some $\bm{x}$ + all $\bm{z}$).

We applied the proposed SMI Modelling algorithm with each of the above predictor combinations, for both variations of the responses concerning the noise level. Moreover, we considered each of the initialisation options discussed in @sec-step1, for each of the two responses.

## Results {#sec-sim-results}

We summarise the results of the simulation experiment in @tbl-simulation. In the columns, we indicate the index structure (i.e. the predictor grouping among indices) estimated by the proposed algorithm under each of the initialisation options. This is detailed for each combination explored, considering response, input predictors, and noise levels.

In the simulation experiment, we did not perform any tuning for the penalty parameters $\lambda_{0}$ and $\lambda_{2}$. Our experiments indicated that, for this simple example, different values of penalty parameters have a negligible impact on the estimated models. The default values $\lambda_{0} = 1$ and $\lambda_{2} = 1$ were used in estimating all the models presented in @tbl-simulation.

```{r}
#| label: tbl-simulation
#| tbl-cap: Simulation experiment results.
#| tbl-pos: "!h"
results_sim <- readr::read_csv(here::here("results/simulation_table_final_edited.csv"))
results_sim <- results_sim[seq(2, NROW(results_sim), by = 2), ]
kable(results_sim,
  format = "latex",
  booktabs = TRUE,
  escape = FALSE,
  linesep = c("", "", "\\addlinespace"),
  col.names = c("True Model", "Predictors", "PPR", "Additive", "Linear", "Multiple")
) |>
  pack_rows(
    index = c("Low noise level" = 6, "High noise level" = 6),
    latex_gap_space = "0.6em"
  ) |>
  row_spec(row = 3, extra_latex_after = "[0.4em]") |>
  row_spec(row = 9, extra_latex_after = "[0.4em]") |>
  kable_styling(latex_options = c("repeat_header", "scale_down")) |>
  row_spec(0, bold = TRUE)
```

At low noise level, in both the cases "all $\bm{x}$" and "all $\bm{x}$ + all $\bm{z}$", all initialisations enable the algorithm to estimate the correct index structure for both $y_{1}$ and $y_{2}$, with an exception in the "Linear" option for $y_{2}$. The "Linear" option for $y_{2}$ selects the correct variables, but fails to identify the 2-index structure. This suggests that initialising the algorithm with a higher number of indices might be more effective than a lower number. In the case of "some $\bm{x}$ + all $\bm{z}$", for both $y_{1}$ and $y_{2}$, the models estimated under all  initialisations include some noise variables. This indicates that when the available predictors are insufficient to capture the data signal, the algorithm might select irrelevant variables to make up for the missing signal.

When the fitted models are evaluated, for $y_{1}$, in both the cases "all $\bm{x}$" and "all $\bm{x}$ + all $\bm{z}$", all initialisations resulted in a test MSE of $\approx 0.01$, which corresponds to the variance of the true model error. This confirms the accuracy with which the SMI Modelling algorithm estimated the index structure for $y_{1}$. For $y_{2}$, all the models estimated resulted in a test MSE of $\approx 0.16$. This is an interesting result as the test MSE of an estimated model with incorrect index structure, but with correct predictors ("Linear") is similar to the models with correct index structure ("PPR", "Additive", and "Multiple"). This suggests that the selection of the predictor variables is more important than determining the index structure of the model. For both $y_{1}$ and $y_{2}$, in the case of "some $\bm{x}$ + all $\bm{z}$", the test MSEs increased in comparison to the above cases, probably due to the inclusion of noise variables.

Moreover, in contrast to $y_{1}$, the test MSE values for $y_{2}$ are higher than the variance of the true model error. Intuitively, the complexity of the model $y_{2}$ is higher than $y_{1}$, where the total estimation error of two nonlinear functions (corresponding to the two indices) for $y_{2}$, might be higher than the error of estimating a single nonlinear function for $y_{1}$.

As expected, the accuracy with which the SMI Modelling algorithm estimates the index structure is in general lower with the high noise level than with the low noise level. For both $y_{1}$ and $y_{2}$, most of the estimated models have selected irrelevant variables. In both the cases "all $\bm{x}$" and "all $\bm{x}$ + all $\bm{z}$", all the models estimated for $y_{1}$ (except for the "Additive" option in the "all $\bm{x}$" case) resulted in a test MSE of $\approx 0.23$ (which is slightly lower than the variance of the true model error) irrespective of the fact that in "all $\bm{x}$ + all $\bm{z}$" case, "Additive" and "Multiple" options included a noise variable. The suggests over-fitting when there is  low signal-to-noise ratio in the data. The observation is the same for $y_{2}$, where irrespective of the different index structures and predictor choices, the estimated models in the above two predictor combinations produced similar test MSE values.

Similar to the previous case of low noise level, when only a part of $\bm{x}$ variables are provided, the test MSE values increased for both $y_{1}$ and $y_{2}$, where the estimated models for $y_{2}$ produced higher test MSE values in comparison to the models for $y_{1}$.

It is worth mentioning here that in real-world forecasting problems, the true data generating process (DGP) is unknown, and we do not expect an estimated model to precisely capture the true DGP. Therefore, as long as the estimated model demonstrates good forecasting accuracy, the index structure of the estimated model is less important.

Finally, the simulation study indicates that the choice of the initialisation depends on the data and application. Thus, users are encouraged to follow a trial-and-error procedure to determine the most suitable initial model for a given application.

# Empirical Applications {#sec-application}


## Forecasting Daily Mortality {#sec-mortality}

We apply the SMI Modelling algorithm to a data set from @Masselot2022, to forecast daily mortality based on heat exposure. Studying the effects of various environmental exposures such as weather related variables, pollutants and man-made environmental conditions on human health, is of significant importance in environmental epidemiology. 

### Description of the Data

For this analysis, we consider daily mortality and heat exposure data for the Metropolitan Area of Montreal, Québec, Canada, from 1990 to 2014, for the months June, July, and August (i.e. summer). The daily all-cause mortality data were obtained from the National Institute of Public Health, Québec, while *DayMet*, a 1 km × 1 km grid data set [@Thornton2021], was used to extract daily temperature and humidity data [@Masselot2022].

@fig-deaths shows the time plots of daily deaths during the summer for the years from 1990 to 1993. The series for each of the four years are presented separately in a faceted grid for visual clarity.

```{r}
#| label: fig-deaths
#| fig-cap: Daily mortality in summer in Montreal, Canada from 1990 to 1993.
dataHeat <- readRDS("data/heat_data_corrected.rds")
dataHeat |>
  mutate(Date = as.POSIXct(Date)) |>
  filter(Date <= "1993-08-31") |>
  ggplot(aes(x = Date, y = Death_lag_000)) +
  geom_line(colour = "grey40") +
  geom_point(colour = "grey40", size = 0.5) +
  facet_wrap(vars(Year), scales = "free_x", ncol = 1, strip.position = "left") +
  scale_x_datetime(date_breaks = "1 month") +
  labs(x = "Date", y = "Number of Deaths", title = "")
```

The three main predictors considered in this empirical study are maximum temperature, minimum temperature, and vapour pressure (to represent the level of humidity). The number of daily deaths are plotted against each of these predictors in Figures [-@fig-Tmax]--[-@fig-Vp], respectively, where we can observe that the relationships between these predictors and the response are slightly non-linear.

```{r}
#| label: fig-Tmax
#| fig-cap: Daily mortality in summer (from 1990 to 2014) plotted against maximum temperature.
dataHeat |>
  ggplot(aes(x = Tmax_lag_000, y = Death_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.5) +
  xlim(c(0, 35)) +
  labs(
    x = "Maximum Temperature (Degrees Celsius)",
    y = "Number of Deaths",
    title = ""
  )
```

```{r}
#| label: fig-Tmin
#| fig-cap: Daily mortality in summer (from 1990 to 2014) plotted against minimum temperature.
dataHeat |>
  ggplot(aes(x = Tmin_lag_000, y = Death_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.5) +
  xlim(c(0, 35)) +
  labs(
    x = "Minimum Temperature (Degrees Celsius)",
    y = "Number of Deaths",
    title = ""
  )
```

```{r}
#| label: fig-Vp
#| fig-cap: Daily mortality in summer (from 1990 to 2014) plotted against vapour pressure.
dataHeat |>
  ggplot(aes(x = Vp_lag_000, y = Death_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.5) +
  labs(x = "Vapour Pressure", y = "Number of Deaths", title = "")
```

\pagebreak[3]

### Predictors Considered

#### 1) Current maximum/minimum temperatures and lags:

In addition to current maximum and minimum temperatures, the temperature measurements up to 14 days prior are considered as predictors in the forecasting model. This accounts for the cumulative impact of both current and recent past temperatures on a person's heat exposure.

#### 2) Current vapour pressure and lags:

Similarly, the current value and 14 lags of vapour pressure are considered as predictors, as a proxy for the level of humidity.

#### 3) Calendar effects:

Finally, a couple of calendar variables (*day of the season (DOS)* and *Year*) are incorporated into the model to capture annual trend and seasonality, and also to control the autocorrelation in residuals, which is a common practice in environmental epidemiology [@Masselot2022].

### Modelling Framework

Maximum temperature lags, minimum temperature lags, and vapour pressure lags are predictors that may enter indices. The two calendar variables, *DOS* and *Year*, are included in the model as separate nonparametric components that do not enter any of the indices. Hence, the relevant SMI Model can be written as
$$
  \textbf{Deaths} = \beta_{0} + \sum_{j = 1}^{p}{g_{j}(\bm{X}\bm{\alpha}_{j})} + f_{1}(\textbf{DOS}) + f_{2}(\textbf{Year})+ \bm{\varepsilon},
$$ {#eq-heat}
where

- $\textbf{Deaths}$ is the vector containing daily deaths observations;
- $\beta_{0}$ is the model intercept;
- $p$ is the unknown number of indices to be estimated via the algorithm;
- $\bm{X}$ is a matrix containing the $q=45$ predictor variables that may enter indices (i.e. maximum temperature lags, minimum temperature lags, and vapour pressure lags);
- $\bm{\alpha}_{j}$, $j = 1, \dots, p$ are the index coefficient vectors, each of length $q$;
- $g_{1}, \dots,g_p$, $f_{1}$, and $f_{2}$ are unknown nonparametric functions; and
- $\bm{\varepsilon}$ is the error term.

The data from 1990 to 2012 are used as the training set to estimate the model, while the data of year 2014 are used as the test set for evaluating forecasting performance. The data from the three summer months of year 2013 are kept aside as a validation set, which is used to estimate benchmark models for comparison purposes.

We apply the proposed SMI Modelling algorithm to the training set to estimate the model. The forecasting accuracy on the test set is evaluated using MSE and Mean Absolute Error (MAE). We assume that the future values of the maximum/minimum temperatures and vapour pressure are known to use in the forecasting model; thus it is a post hoc analysis.

### Results

We estimated SMI Models for the mortality data using three different initialisation options: "PPR", "Additive" and "Linear", for comparison purposes. We tuned the penalty parameters $\lambda_{0}$ and $\lambda_{2}$ over ranges of integers from 1 to 12, and 0 to 12 respectively, based on in-sample MSE. Here, a greedy search is used instead of a grid search to reduce computational time.

The penalty parameter combination $(\lambda_{0} = 12, \lambda_{2} = 0)$ was selected for the model fitted with "PPR" initialisation. The estimated model, ***SMI Model (12, 0) - PPR ***, resulted in five indices without dropping any of the index variables. The optimal penalty parameter combination for the model initiated with "Additive" was $(\lambda_{0} = 1, \lambda_{2} = 0)$, resulting in the ***SMI Model (1, 0) - Additive ***, equivalent to a nonparametric additive model (no index variables or indices were dropped). The model estimated with "Linear" initialisation selected $(\lambda_{0} = 12, \lambda_{2} = 5)$ (***SMI Model (12, 5) - Linear ***), and resulted in two indices, without dropping any of the index variables.

We evaluated forecasting errors of the estimated models using two subsets of the original test set:

1. ***Test Set 1:*** original test set spanning 3 months (June, July and August 2014); and
2. ***Test Set 2:*** a test set covering 1 month (June 2014).

The MSE and MAE values for the estimated SMI Models on two different test sets are presented in @tbl-heat. We observe that the SMI Model estimated with "PPR" initialisation, ***SMI Model (12, 0) - PPR ***, shows the best forecasting performance on both test sets, compared to the other two estimated SMI models.

```{r}
#| label: tbl-heat
#| tbl-cap: Daily mortality forecasting - Out-of-sample point forecast results.
#| tbl-pos: "!hb"
results_heat <- readr::read_csv("data/heat_results_corrected.csv")
kable(results_heat,
    format = "latex",
    booktabs = TRUE,
    digits = 3,
    escape = FALSE,
    linesep = "",
    col.names = c("Model", "Predictors", "Indices", "MSE", "MAE", "MSE", "MAE")
  ) |>
  add_header_above(c("", "", "", "Test Set 1" = 2, "Test Set 2" = 2), align = "c") |>
  kable_styling(latex_options = c("repeat_header")) |>
  row_spec(0, align = "c") |>
  column_spec(4, bold = if_else(results_heat$MSE1 == min(results_heat$MSE1), TRUE, FALSE)) |>
  column_spec(5, bold = if_else(results_heat$MAE1 == min(results_heat$MAE1), TRUE, FALSE)) |>
  column_spec(6, bold = if_else(results_heat$MSE2 == min(results_heat$MSE2), TRUE, FALSE)) |>
  column_spec(7, bold = if_else(results_heat$MAE2 == min(results_heat$MAE2), TRUE, FALSE))
```

### Benchmark Methods {#sec-benchmark}

We also present the forecasting errors of three benchmark models in @tbl-heat for comparison with the estimated SMI Models. 

The first benchmark is a nonparametric additive model formulated through **backward elimination**, as proposed by @FH2012. The process starts with all variables included in an additive model, and variables are progressively omitted until the optimal model is obtained based on a validation set. 

The second benchmark is a ***Group-wise Additive Index Model (GAIM)***, which can be written in the form
$$
  y_{i} = \sum_{j = 1}^{p} g_{j}(\bm{\alpha}_{j}^{T}\bm{x}_{ij}) + \varepsilon_{i}, 
$$
where $y_{i}$ is the univariate response, $\bm{x}_{ij} \in \mathbb{R}^{l{j}}$, $j = 1, \dots, p$ are pre-specified non-overlapping subsets of $\bm{x}_{i}$, and $\bm{\alpha}_j$ are the corresponding index coefficients, $g_{j}$ is an unknown (possibly nonlinear) component function, and $\varepsilon_{i}$ is the random error, which is independent of $\bm{x}_{i}$ [@Wang2015-mp; @Masselot2022].
For this model, maximum temperature lags, minimum temperature lags, and vapour pressure lags are categorised into three groups, where an index estimated for each group. 

The third benchmark is a ***Projection Pursuit Regression (PPR)*** model [@Friedman1981] given by
$$
  y_{i} = \sum_{j=1}^{p} {g_{j}(\bm{\alpha}_{j}^{T}\bm{x}_{i})} + \varepsilon_{i},
$$
where $y_{i}$ is the response, $\bm{x}_{i}$ is the $q$-dimensional predictor vector, $\bm{\alpha}_{j} = ( \alpha_{j1}, \dots, \alpha_{jp} )^{T}$, $j = 1, \dots, p$ are $q$-dimensional projection vectors (or vectors of "index coefficients"), $g_{j}$'s are unknown nonlinear functions, and $\varepsilon_{i}$ is the random error. The number of indices in the PPR model was taken as 3, matching the number of indices estimated by the GAIM.

@tbl-heat shows that ***SMI Model (12, 0) - PPR*** outperforms all three benchmark models in terms of forecasting accuracy, for both *Test Set 1* and *Test Set 2*. However, the SMI Models estimated using "Additive" or "Linear" initialisations have inferior forecasting performance compared to all benchmark models considered. The actual number of deaths and the predicted values from the ***SMI Model (12, 0) - PPR*** and benchmark models on *Test Set 2* are plotted in @fig-heatPred for further comparison.

```{r}
#| label: fig-heatPred
#| fig-cap: Actual number of deaths vs. predicted number of deaths from "SMI Model (12, 0) - PPR" and benchmark models for Test Set 2.
readr::read_csv(here::here("data/heat_predictions_corrected.csv")) |> 
  select(-SMImodel_Additive, -SMImodel_Linear) |> 
  rename(
    `SMI Model (12, 0) - PPR` = SMImodel_PPR,
    `Backward Elimination` = Backward
  ) |> 
  tidyr::pivot_longer(Actual:GAIM, names_to = "Series", values_to = "Deaths") |> 
  ggplot(aes(x = Date, y = Deaths, colour = Series)) +
  geom_line() +
  scale_x_date(date_breaks = "7 days") +
  labs(x = "Date", y = "Number of Deaths") +
  ggtitle("Actual vs. Predicted Number of Deaths") +
  scale_colour_manual(name = "Series", values = c(
    "Actual" = "grey",
    "SMI Model (12, 0) - PPR" = "#D55E00",
    "PPR" = "#0072B2",
    "Backward Elimination" = "#009E73",
    "GAIM" = "#CC79A7"
  )) +
  theme(
    legend.position = "bottom",
    legend.box = "vertical"
  )
```

\pagebreak

## Forecasting Daily Solar Intensity {#sec-solar}

Next, we utilise the SMI Modelling algorithm to forecast daily solar intensity, using other weather conditions.

### Description of the Data

We use solar intensity and other weather variables measured at the Davis weather station in Amherst, Massachusetts, obtained from the *UMass Trace Repository* [@Umass2023]. The data was recorded at every five minutes, from 21 February 2006 to 27 February 2013, using sensors for measuring temperature, wind chill, humidity, dew point, wind speed, wind direction, rain, pressure, solar intensity, and UV. We converted the five minutes data to daily data by averaging each variable.

@fig-solar shows the time plot of daily solar intensity for the entire period, which clearly depicts the annual seasonality in the data. The gaps show days for which the observations were missing; these were excluded from the analysis.

```{r}
#| label: fig-solar
#| fig-height: 3.5
#| fig-cap: Daily solar intensity in Amherst, Massachusetts, from February 2006 to February 2013.
dataSolar <- readRDS("data/solar_daily_large_final.rds") |> 
  as_tsibble(index = Date) |> 
  fill_gaps() 
dataSolar |> 
  ggplot(aes(x = Date, y = Solar_lag_000)) +
  geom_line(colour = "grey40") +
  scale_x_date(date_breaks = "1 year") +
  labs(title = "", y = "Solar Intensity (Watts per square metre)")
```

In @fig-preds, the daily solar intensity is plotted against each of the predictors: temperature, dew point, wind, rain and humidity. We can observe that the relationships between these predictors and the response are non-linear.

```{r}
#| label: fig-preds
#| fig-height: 8
#| fig-cap: Daily solar intensity against other weather variables.
p1 <- dataSolar |>
  ggplot(aes(x = Temp_lag_000, y = Solar_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.5, size = 0.3) +
  xlim(c(-25, 90)) +
  xlab("Temperature (Degrees Fahrenheit)") +
  ylab("Solar Intensity") +
  ggtitle("Solar Intensity against Temperature") +
  theme(
    axis.title = element_text(size = 6),
    plot.title = element_text(size = 8)
  )

p2 <- dataSolar |>
  ggplot(aes(x = Dewpt_lag_000, y = Solar_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.5, size = 0.3) +
  xlim(c(-25, 90)) +
  xlab("Dew Point (Degrees Fahrenheit)") +
  ylab("Solar Intensity") +
  ggtitle("Solar Intensity against Dew Point") +
  theme(
    axis.title = element_text(size = 6),
    plot.title = element_text(size = 8)
  )

p3 <- dataSolar |>
  ggplot(aes(x = Wind_lag_000, y = Solar_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.5, size = 0.3) +
  xlab("Wind Speed (Miles per hour)") +
  ylab("Solar Intensity") +
  ggtitle("Solar Intensity against Wind Speed") +
  theme(
    axis.title = element_text(size = 6),
    plot.title = element_text(size = 8)
  )

p4 <- dataSolar |>
  ggplot(aes(x = Rain_lag_000, y = Solar_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.5, size = 0.3) +
  xlab("Rain (Inches)") +
  ylab("Solar Intensity") +
  ggtitle("Solar Intensity against Rain") +
  theme(
    axis.title = element_text(size = 6),
    plot.title = element_text(size = 8)
  )

p5 <- dataSolar |>
  ggplot(aes(x = Humid_lag_000, y = Solar_lag_000)) +
  geom_point(colour = "grey40", alpha = 0.5, size = 0.3) +
  xlab("Humidity (Percentage)") +
  ylab("Solar Intensity") +
  ggtitle("Solar Intensity against Humidity") +
  theme(
    axis.title = element_text(size = 6),
    plot.title = element_text(size = 8)
  )

grid.arrange(p1, p2, p3, p4, p5, nrow = 3, ncol = 2)
```

### Predictors Considered

#### 1) Solar intensity lags:

Three lags of the daily solar intensity itself are used as predictors to incorporate the serial correlations presented in the data into the modelling process.

#### 2) Current weather variables and lags:

In addition to current temperature, dew point, wind speed, rain and humidity, the measurements of the three previous days for each of the these weather variables are also included as predictors in the forecasting model.

#### 3) Calendar effects:

Finally, a calendar variable, *Month* (12 months of the year), is incorporated into the model to capture annual seasonality, and control for autocorrelation in residuals.

### Modelling Framework

The lags of solar intensity, and the lags of weather variables are considered as predictors that may  enter indices. The calendar variable *Month* is included into the model as a linear (categorical) predictor variable.

Hence, the relevant SMI Model can be written as
$$
  \textbf{Solar} = \beta_{0} + \sum_{j = 1}^{p}{g_{j}(\bm{X}\bm{\alpha}_{j})} + \bm{M}\bm{\theta} + \bm{\varepsilon},
$$ {#eq-solar}
where

- $\textbf{Solar}$ is the vector containing daily observations of solar intensity;
- $\beta_{0}$ is the model intercept;
- $p$ is the unknown number of indices to be estimated via the algorithm;
- $\bm{X}$ is a matrix containing the $q=23$ predictor variables that may enter indices (i.e. solar intensity, temperature, dew point, wind speed, rain and humidity lags);
- $\bm{\alpha}_{j}$, $j = 1, \dots, p$ are the index coefficient vectors, each of length $q$;
- $g_{1}, \dots, g_{p}$ are unknown nonparametric functions;
- $\bm{M}$ is a matrix containing the $11$ dummy variables corresponding to the categorical variable *Month* (month January is taken as the base level);
- $\bm{\theta}$ is a vector of coefficients of length $11$ corresponding to the dummy variables in $\bm{M}$; and
- $\bm{\varepsilon}$ is the error term.

The data from February 2006 to October 2012 are used as the training set to estimate the model, while the data of January and February 2013 comprise the test set to evaluate the forecasting performance. The data from November and December 2013 are kept aside as a validation set, which is required to estimate some of the benchmark models for comparison.

Then we apply the proposed SMI Modelling algorithm to the training set to estimate the model, and the forecasting accuracy on the test set is evaluated using MSE and MAE. We assumed that the future values of the weather variables are known; thus it is a post hoc analysis.

### Results

We estimated SMI Models for the solar intensity data using three different initialisation options: "PPR", "Additive" and "Linear". We also tuned the penalty parameters $\lambda_{0}$ and $\lambda_{2}$, over ranges of integers from 1 to 12, and 0 to 12 respectively.

The penalty parameter combination $(\lambda_{0} = 1, \lambda_{2} = 12)$ was selected for the model fitted with "PPR" initialisation. The estimated model, ***SMI Model (1, 12) - PPR ***, resulted in five indices without dropping any of the index variables. The optimal penalty parameter combination for the model estimated taking "Additive" model as the starting point was $(\lambda_{0} = 1, \lambda_{2} = 0)$. The estimated SMI Model did not drop any index variables or indices, and thus the final model, ***SMI Model (1, 0) - Additive ***, is equivalent to a nonparametric additive model. The model estimated with "Linear" initialisation also selected $(\lambda_{0} = 1, \lambda_{2} = 0)$. Unlike the above models, this SMI Model dropped all index variables and resulted in null indices, and hence, the final model, ***SMI Model (1, 0) - Linear ***, is just a linear model with the two linear variables *Month* and *Season*. Notice that all three estimated SMI Models have $\lambda_{2} = 0$, indicating that all three models have omitted the $\ell_{2}$-penalty in the estimation process.

@tbl-solar presents the MSE and MAE values for the estimated SMI Models on the test set. The results indicate that the SMI Model estimated with "Additive" initialisation, ***SMI Model (1, 0) - Additive***, shows the best forecasting performance among the three estimated SMI Models.

We also present forecasting errors of the three benchmark models in @tbl-solar, to compare with the estimated SMI Models. Here, the GAIM is fitted by grouping the lags of each weather variable into a different group, resulting in six indices. The number of indices of the PPR model was taken as six, matching the number of indices estimated by the GAIM. Note that here, the categorical calendar variable was excluded when estimating the PPR model.

```{r}
#| label: tbl-solar
#| tbl-cap: Daily solar intensity forecasting - Out-of-sample point forecast results.
results_solar <- readr::read_csv("results/solar_results.csv")
kable(results_solar,
  format = "latex",
  booktabs = TRUE,
  digits = 3,
  linesep = "",
  escape = FALSE,
  col.names = c("Model", "Predictors", "Indices", "MSE", "MAE")
) |>
  add_header_above(c("", "", "", "Test Set" = 2), align = "c") |>
  kable_styling(latex_options = c("repeat_header")) |>
  row_spec(0, align = "c") |>
  column_spec(4, bold = if_else(results_solar$MSE == min(results_solar$MSE), TRUE, FALSE)) |>
  column_spec(5, bold = if_else(results_solar$MAE == min(results_solar$MAE), TRUE, FALSE))
```

According to @tbl-solar, the forecasting errors of ***SMI Model (1, 0) - Additive*** is lower than the GAIM. However, the ***SMI Model (1, 0) - Additive*** is unable to outperform both the semi-parametric additive model with backward elimination and the PPR model, where in this case, the estimated PPR model has resulted in the best forecasting accuracy.

Here, it is worth considering the differences between the SMI Model and the benchmark models that show superior forecasting performance. The method proposed by @FH2012 formulates a semi-parametric additive model using a backward elimination of predictors. When estimating a PPR model, both the number of indices and the predictors within each index (each index includes all provided predictors that are entering indices) are pre-determined. In contrast, the SMI Model takes a more general and objective approach, where the number of indices as well as predictors within each index are automatically determined through the proposed algorithm. Thus, the SMI Model faces a more challenging estimation task due to the limited prior information provided.

The actual solar intensity and the predicted values from the SMI Model (1, 0) - Additive and benchmark models are plotted in @fig-solarPred for further comparison.

```{r}
#| label: fig-solarPred
#| fig-cap: Actual solar intensity vs. predicted solar intensity from "SMI Model (1, 0) - Additive" and benchmark models.
SolarPreds <- readr::read_csv("results/solar_predictions.csv") |> 
  rename(
    `SMI Model (1,0) - Additive` = SMImodel_Additive,
    `Backward Elimination` = Backward
  ) |> 
  select(-SMImodel_Linear, -SMImodel_PPR) |> 
  tidyr::pivot_longer(Actual:GAIM, names_to = "Series", values_to = "Intensity")
SolarPreds |> 
  ggplot(aes(x = Date, y = Intensity, colour = Series)) +
  geom_line() +
  scale_x_date(date_breaks = "7 days") +
  labs(
    x = "Date", y = "Solar Intensity (Watts per square metre)",
    title = "Actual vs. Predicted Solar Intensity"
  ) +
  scale_colour_manual(name = "Series", values = c(
    "Actual" = "grey",
    "SMI Model (1,0) - Additive" = "#D55E00",
    "PPR" = "#0072B2",
    "Backward Elimination" = "#009E73",
    "GAIM" = "#CC79A7"
  )) +
  theme(
    legend.position = "bottom",
    legend.box = "vertical"
  )
```

## Software

These two empirical applications were performed using the R statistical software [@Rcore]. We used the commercial MIP solver ***Gurobi*** [@gurobi2023] to solve the MIQPs related to the proposed SMI Modelling algorithm, through the ***Gurobi plug-in*** [ROI.plugin.gurobi, @Schwendinger2023] available from the ***R Optimization Infrastructure*** [ROI, @Hornik2023; @Theusl2020] package. Furthermore, the GAMs were fitted using the R package ***mgcv*** [@mgcv;@Wood2011].

# Conclusions and Further Research {#sec-conclusion}

In this paper, we presented a novel algorithm for estimating a nonparametric additive index model with optimal predictor selection, which we refer to as Sparse Multiple Index (SMI) Model. The SMI Modelling algorithm is an iterative procedure that is developed based on mixed integer programming to solve an $\ell_{0}$-regularised nonlinear least squares optimisation problem with linear constraints.

The proposed SMI Modelling algorithm has a number of key features: 1) It performs automatic selection of both the number of indices and the predictor grouping when estimating the nonparametric additive index model. Users need to input the set of predictors entering indices and a starting model (index structure and a set of index coefficients) to initiate the algorithm. 2) It performs automatic variable selection, which is particularly beneficial in high-dimensional settings. This feature contributes to an objective and principled estimation, reducing subjectivity across different users. 3) It is capable of estimating a wide spectrum of models, from single index models (one index) to additive models (number of indices equals the number of predictors entering indices). Hence, the SMI Modelling algorithm is a more general estimation tool for nonparametric additive models. 4) It provides the flexibility to include separate non-liner and linear predictors in the model that are not entering any indices, allowing the estimation of semi-parametric additive models.

Due to the limited input information provided to the algorithm, the estimation of a SMI Model is a challenging problem. We demonstrated the performance of the proposed algorithm through a simulation study and two empirical applications. 

The two empirical applications presented above highlight the challenge of finding a universally applicable initialisation option for the SMI Model across various applications. As mentioned in @sec-simulation, we encourage users to follow a trial-and-error procedure to identify the most effective initialisation option for their specific application.

A limitation of the proposed algorithm is the difficulty of specifying an initialisation that works in general. Hence, an interesting future research problem would be to explore the potential for determining a generalised initialisation for the SMI Modelling algorithm that will work across various applications.

This study should be viewed as a first attempt to develop a more objective methodology for variable selection and model estimation in the broader class of nonparametric additive models for forecasting. An important future research problem is therefore, to assess the performance of the proposed SMI Modelling algorithm across various data sets with diverse properties, identifying scenarios where it outperforms other benchmark methods.

Furthermore, the MIQP in the algorithm is somewhat analogous to the *best subset selection* method frequently used in least squares problems. Thus, another limitation of the proposed algorithm is the increase in computational time as the number of predictors and number of indices increase. Therefore, it would be an interesting research to obtain further insights regarding the algorithm to see what improvements can be made to the algorithm design to reduce the computational cost in a high-dimensional context.

# Acknowledgements {-}

We thank Professor Louise Ryan for useful discussions during the initial stage of the project, and for her valuable comments and feedback on this research work.

Furthermore, this research is partially supported by the Monash eResearch Centre through the use of the MonARCH (Monash Advanced Research Computing Hybrid) HPC Cluster, and by the Australian Research Council Industrial Transformation Training Centre in Optimisation Technologies, Integrated Methodologies, and Applications (OPTIMA), Project ID IC200100009. 
